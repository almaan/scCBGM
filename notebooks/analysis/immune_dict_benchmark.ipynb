{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a3286f",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225a171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c2a14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afbd528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conceptlab as clab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import scipy.spatial\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "import string\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import pytorch_lightning as pl\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c17dc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdef7d30090>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = '/braid/havivd/immune_dictionary/lig_seurat_with_concepts.h5ad'\n",
    "OBSM_KEY = 'X_pca'\n",
    "Z_SCORE = False\n",
    "CONCEPT_KEY = 'concepts'\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81323653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1da2c3",
   "metadata": {},
   "source": [
    "# DATA LOADING AND PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f65d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(adata, hold_out_label, mod_label, label_key = 'L2_stim'):\n",
    "    \"\"\"\n",
    "    Splits data into train, intervention, and ground truth sets.\n",
    "\n",
    "    - Ground Truth: All cells with the `hold_out_label`.\n",
    "    - Intervention: All cells with the `mod_label`.\n",
    "    - Train: All remaining cells.\n",
    "    \"\"\"\n",
    "    print(\"Splitting data with simplified logic...\")\n",
    "    labels = adata.obs[label_key]\n",
    "\n",
    "    # Define the three disjoint sets based on their labels\n",
    "    is_test = (labels == hold_out_label)\n",
    "    is_inter = (labels == mod_label)\n",
    "    is_train = ~is_test\n",
    "\n",
    "    # Create AnnData objects for each split\n",
    "    adata_train = adata[is_train].copy()\n",
    "    adata_test = adata[is_test].copy()\n",
    "    adata_inter = adata[is_inter].copy()\n",
    "\n",
    "    # Store split identifiers in the original object\n",
    "    ident_vec = np.array(['train'] * len(adata)).astype('<U32')\n",
    "    ident_vec[is_test] = 'held out as GT'\n",
    "    ident_vec[is_inter] = 'intervention'\n",
    "    adata.obs['ident'] = ident_vec\n",
    "    \n",
    "\n",
    "    return adata, adata_train, adata_test, adata_inter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce377a4a",
   "metadata": {},
   "source": [
    "# MODELING & PREDICTION METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8637333d",
   "metadata": {},
   "source": [
    "## Method 1: scCBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "117fa200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cbgm(adata_train, concept_key = 'concepts', obsm_key = 'X_pca'):\n",
    "    \"\"\"Trains and returns the scCBGM model.\"\"\"\n",
    "    print(\"Training scCBGM model...\")\n",
    "\n",
    "    # --- MODIFICATION START ---\n",
    "    # Conditionally set the data source and input dimension based on the 'pca' flag\n",
    "    if(obsm_key != 'X'):\n",
    "        data_matrix = adata_train.obsm[obsm_key]\n",
    "    else:\n",
    "        data_matrix = adata_train.X\n",
    "    # --- MODIFICATION END ---\n",
    "\n",
    "    torch.set_flush_denormal(True)\n",
    "\n",
    "    config = OmegaConf.create(dict(\n",
    "        has_cbm=True, \n",
    "        lr=3e-4, \n",
    "        hidden_dim=1024, \n",
    "        n_layers = 4,\n",
    "        beta=1e-5,\n",
    "        input_dim=data_matrix.shape[-1],  # <-- Use the dynamically set input dimension\n",
    "        latent_dim=128,\n",
    "        n_concepts=adata_train.obsm[concept_key].shape[1],\n",
    "        n_unknown=128, \n",
    "        concepts_hp=0.1, \n",
    "        orthogonality_hp=0.5, \n",
    "        use_soft_concepts=False\n",
    "    ))\n",
    "    model = clab.models.scCBGM(config)\n",
    "\n",
    "    model.train_loop(\n",
    "        data=torch.from_numpy(data_matrix.astype(np.float32)),\n",
    "        concepts=torch.from_numpy(adata_train.obsm[concept_key].to_numpy().astype(np.float32)),\n",
    "        num_epochs=200, batch_size=128)\n",
    "    return model\n",
    "\n",
    "\n",
    "def pred_cbgm(model, adata_inter,  ctrl_index, stim_index, concept_key = 'concepts', obsm_key = 'X_pca'):\n",
    "    \"\"\"Performs intervention using a trained scCBGM model.\"\"\"\n",
    "    print(\"Performing intervention with scCBGM...\")\n",
    "    if(obsm_key != 'X'):\n",
    "        x_intervene_on = torch.tensor(adata_inter.obsm[obsm_key], dtype=torch.float32)\n",
    "    else:\n",
    "        x_intervene_on = torch.tensor(adata_inter.X, dtype=torch.float32)\n",
    "    c_intervene_on = adata_inter.obsm[concept_key].to_numpy().astype(np.float32)\n",
    "\n",
    "    # Define the intervention by creating a mask and new concept values\n",
    "    mask = torch.zeros(c_intervene_on.shape, dtype=torch.float32)\n",
    "    mask[:, ctrl_index] = 1  # Intervene on the last concept (stim)\n",
    "    mask[:, stim_index] = 1  # Intervene on the last concept (stim)\n",
    "    \n",
    "    inter_concepts = torch.tensor(c_intervene_on, dtype=torch.float32)\n",
    "    inter_concepts[:, ctrl_index] = 0 # Set ctrl concept to 0\n",
    "    inter_concepts[:, stim_index] = 1 # Set stim concept to 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inter_preds = model.intervene(x_intervene_on.to('cuda'), mask=mask.to('cuda'), concepts=inter_concepts.to('cuda'))\n",
    "    \n",
    "    inter_preds = inter_preds['x_pred'].cpu().numpy()\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        x_inter_preds = np.zeros_like(adata_inter.X)\n",
    "    else:\n",
    "        x_inter_preds = inter_preds\n",
    "\n",
    "    pred_adata = adata_inter.copy()\n",
    "    pred_adata.X = x_inter_preds\n",
    "    pred_adata.obs['ident'] = 'intervened on'\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        pred_adata.obsm[obsm_key] = inter_preds\n",
    "    return pred_adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec223ed8",
   "metadata": {},
   "source": [
    "##  Method 2: Flow Matching with Learned Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "640c4957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learned_concepts(scCBGM_model, adata_full, obsm_key = 'X_pca'):\n",
    "    \"\"\"Uses a trained scCBGM to generate learned concepts for all data.\"\"\"\n",
    "    print(\"Generating learned concepts from scCBGM...\")\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        all_x = torch.tensor(adata_full.obsm[obsm_key], dtype=torch.float32).to('cuda')\n",
    "    else:\n",
    "        all_x = torch.tensor(adata_full.X, dtype=torch.float32).to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enc = scCBGM_model.encode(all_x)\n",
    "        adata_full.obsm['scCBGM_concepts_known'] = scCBGM_model.cb_concepts_layers(enc['mu']).cpu().numpy()\n",
    "        adata_full.obsm['scCBGM_concepts_unknown'] = scCBGM_model.cb_unk_layers(enc['mu']).cpu().numpy()\n",
    "\n",
    "    adata_full.obsm['scCBGM_concepts'] = np.concatenate([adata_full.obsm['scCBGM_concepts_known'], adata_full.obsm['scCBGM_concepts_unknown']], axis=1)\n",
    "    return adata_full\n",
    "\n",
    "def train_cb_fm(adata_train, concept_key = 'scCBGM_concepts', obsm_key = 'X_pca'):\n",
    "    \"\"\"Trains and returns the CB-FM model using learned concepts.\"\"\"\n",
    "    print(\"Training Concept Bottleneck Flow Model\")\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        data_matrix = adata_train.obsm[obsm_key]\n",
    "    else:\n",
    "        data_matrix = adata_train.X\n",
    "    \n",
    "    config = dict(\n",
    "        input_dim=data_matrix.shape[1],\n",
    "        hidden_dim=1024,\n",
    "        latent_dim=128,\n",
    "        n_concepts=adata_train.obsm[concept_key].shape[1],\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "        p_uncond = 0.0)\n",
    "\n",
    "    fm_model = clab.models.cond_fm.Cond_FM(config=config)\n",
    "\n",
    "    fm_model.train_loop(\n",
    "        data=torch.from_numpy(data_matrix.astype(np.float32)),\n",
    "        concepts=torch.from_numpy(adata_train.obsm[concept_key].astype(np.float32)),\n",
    "        num_epochs=200, batch_size=128, lr=3e-4,\n",
    "    )\n",
    "    return fm_model\n",
    "\n",
    "\n",
    "\n",
    "def pred_cb_fm(model, adata_inter, ctrl_index, stim_index, concept_key = 'scCBGM_concepts', obsm_key = 'X_pca', edit = True):\n",
    "    \"\"\"Performs intervention using a trained learned-concept CB-FM model.\"\"\"\n",
    "    print(\"Performing intervention with CB-FM (learned)...\")\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        x_inter = adata_inter.obsm[obsm_key]\n",
    "    else:\n",
    "        x_inter = adata_inter.X\n",
    "    \n",
    "\n",
    "    init_concepts = adata_inter.obsm[concept_key].astype(np.float32)\n",
    "\n",
    "    edit_concepts = init_concepts.copy()\n",
    "    edit_concepts[:, ctrl_index] = 0 # Set ctrl concept to 0\n",
    "    edit_concepts[:, stim_index] = 1 # Set stim concept to 1\n",
    "\n",
    "\n",
    "    if(edit):\n",
    "        inter_preds = model.edit(\n",
    "                x = torch.from_numpy(x_inter.astype(np.float32)).to('cuda'),\n",
    "                c = torch.from_numpy(init_concepts.astype(np.float32)).to('cuda'),\n",
    "                c_prime = torch.from_numpy(edit_concepts.astype(np.float32)).to('cuda'),\n",
    "                t_edit = 0.0,\n",
    "                n_steps = 1000,\n",
    "                w_cfg_forward = 1.0,\n",
    "                w_cfg_backward = 1.0,\n",
    "                noise_add = 0.0)\n",
    "    else:\n",
    "        inter_preds = model.decode(\n",
    "                h = torch.from_numpy(edit_concepts.astype(np.float32)).to('cuda'),\n",
    "                n_steps = 1000,\n",
    "                w_cfg = 1.0)\n",
    "        \n",
    "    inter_preds = inter_preds.detach().cpu().numpy()\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        x_inter_preds = np.zeros_like(adata_inter.X)\n",
    "    else:\n",
    "        x_inter_preds = inter_preds\n",
    "\n",
    "    pred_adata = adata_inter.copy()\n",
    "    pred_adata.X = x_inter_preds\n",
    "    pred_adata.obs['ident'] = 'intervened on'\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        pred_adata.obsm[obsm_key] = inter_preds\n",
    "    return pred_adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db46e42",
   "metadata": {},
   "source": [
    "## Method 3: Flow Matching with Raw Concepts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b6d9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_raw_fm(adata_train, concept_key = 'concepts', obsm_key = 'X_pca'):\n",
    "    \"\"\"Trains and returns the CB-FM model using learned concepts.\"\"\"\n",
    "    print(\"Training Conditonal Flow Model\")\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        data_matrix = adata_train.obsm[obsm_key]\n",
    "    else:\n",
    "        data_matrix = adata_train.X\n",
    "    \n",
    "    config = dict(\n",
    "        input_dim=data_matrix.shape[1],\n",
    "        hidden_dim=1024,\n",
    "        latent_dim=128,\n",
    "        n_concepts=adata_train.obsm[concept_key].to_numpy().shape[1],\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "        p_uncond = 0.0)\n",
    "\n",
    "    fm_model = clab.models.cond_fm.Cond_FM(config=config)\n",
    "\n",
    "    fm_model.train_loop(\n",
    "        data=torch.from_numpy(data_matrix.astype(np.float32)),\n",
    "        concepts=torch.from_numpy(adata_train.obsm[concept_key].to_numpy().astype(np.float32)),\n",
    "        num_epochs=200, batch_size=128, lr=3e-4,\n",
    "    )\n",
    "    return fm_model\n",
    "\n",
    "\n",
    "\n",
    "def pred_raw_fm(model, adata_inter, ctrl_index, stim_index, concept_key = 'concepts', obsm_key = 'X_pca', edit = False):\n",
    "    \"\"\"Performs intervention using a trained learned-concept CB-FM model.\"\"\"\n",
    "    print(\"Performing intervention with Raw Flow Matching(learned)...\")\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        x_inter = adata_inter.obsm[obsm_key]\n",
    "    else:\n",
    "        x_inter = adata_inter.X\n",
    "    \n",
    "\n",
    "    init_concepts = adata_inter.obsm[concept_key].to_numpy().astype(np.float32)\n",
    "\n",
    "    edit_concepts = init_concepts.copy()\n",
    "    edit_concepts[:, ctrl_index] = 0 # Set ctrl concept to 0\n",
    "    edit_concepts[:, stim_index] = 1 # Set stim concept to 1\n",
    "    \n",
    "\n",
    "\n",
    "    if(edit):\n",
    "        inter_preds = model.edit(\n",
    "                x = torch.from_numpy(x_inter.astype(np.float32)).to('cuda'),\n",
    "                c = torch.from_numpy(init_concepts).to('cuda'),\n",
    "                c_prime = torch.from_numpy(edit_concepts).to('cuda'),\n",
    "                t_edit = 0.0,\n",
    "                n_steps = 1000,\n",
    "                w_cfg_forward = 1.0,\n",
    "                w_cfg_backward = 1.0,\n",
    "                noise_add = 0.0)\n",
    "    else:\n",
    "        inter_preds = model.decode(\n",
    "                h = torch.from_numpy(edit_concepts).to('cuda'),\n",
    "                n_steps = 1000,\n",
    "                w_cfg = 1.0)\n",
    "    \n",
    "    inter_preds = inter_preds.detach().cpu().numpy()\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        x_inter_preds = np.zeros_like(adata_inter.X)\n",
    "    else:\n",
    "        x_inter_preds = inter_preds\n",
    "\n",
    "    pred_adata = adata_inter.copy()\n",
    "    pred_adata.X = x_inter_preds\n",
    "    pred_adata.obs['ident'] = 'intervened on'\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        pred_adata.obsm[obsm_key] = inter_preds\n",
    "    return pred_adata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03651909",
   "metadata": {},
   "source": [
    "# Method 4: CB VAE FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "896f5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cb_fm_vae(adata_train, concept_key = 'concepts', obsm_key = 'X_pca', kl_hp = 0.1, concepts_hp = 0.2, orthogonality_hp = 0.5):\n",
    "    \"\"\"Trains and returns the scCBGM model.\"\"\"\n",
    "    print(\"Training Concept Flow Model\")\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        data_matrix = adata_train.obsm[obsm_key]\n",
    "    else:\n",
    "        data_matrix = adata_train.X\n",
    "\n",
    "    config = dict(\n",
    "        input_dim=data_matrix.shape[1],\n",
    "        hidden_dim=1024,\n",
    "        latent_dim=128,\n",
    "        n_concepts=adata_train.obsm[concept_key].to_numpy().shape[1],\n",
    "        n_unknown=128,\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "        p_uncond=0.0,\n",
    "        unknown_activation = 'relu',\n",
    "        kl_hp = kl_hp,\n",
    "        concepts_hp=concepts_hp, \n",
    "        orthogonality_hp=orthogonality_hp,\n",
    "        flow_hp = 1.0)\n",
    "\n",
    "    fm_model = clab.models.concept_fm.Concept_FM(config=config)\n",
    "\n",
    "    fm_model.train_loop(\n",
    "        data=torch.from_numpy(data_matrix.astype(np.float32)),\n",
    "        concepts=torch.from_numpy(adata_train.obsm[concept_key].to_numpy().astype(np.float32)),\n",
    "        num_epochs=200, batch_size=128, lr=3e-4,\n",
    "    )\n",
    "    return fm_model\n",
    "\n",
    "\n",
    "def pred_cb_fm_vae(model, adata_inter, ctrl_index, stim_index, concept_key = 'concepts', obsm_key = 'X_pca'):\n",
    "    \"\"\"Performs intervention using a trained CB_FM_VAE model.\"\"\"\n",
    "    print(\"Performing intervention with CB_FM_VAE...\")\n",
    "    if(obsm_key != 'X'):\n",
    "        x_intervene_on = torch.tensor(adata_inter.obsm[obsm_key], dtype=torch.float32)\n",
    "    else:\n",
    "        x_intervene_on = torch.tensor(adata_inter.X, dtype=torch.float32)\n",
    "    c_intervene_on = adata_inter.obsm[concept_key].to_numpy().astype(np.float32)\n",
    "\n",
    "    # Define the intervention by creating a mask and new concept values\n",
    "    mask = torch.zeros(c_intervene_on.shape, dtype=torch.float32)\n",
    "    mask[:, ctrl_index] = 1  # Intervene on the last concept (stim)\n",
    "    mask[:, stim_index] = 1  # Intervene on the last concept (stim)\n",
    "    \n",
    "    inter_concepts = torch.tensor(c_intervene_on, dtype=torch.float32)\n",
    "    inter_concepts[:, ctrl_index] = 0 # Set ctrl concept to 0\n",
    "    inter_concepts[:, stim_index] = 1 # Set stim concept to 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inter_preds = model.intervene(x_intervene_on.to('cuda'), mask=mask.to('cuda'), concepts=inter_concepts.to('cuda'))\n",
    "    \n",
    "    inter_preds = inter_preds.cpu().numpy()\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        x_inter_preds = np.zeros_like(adata_inter.X)\n",
    "    else:\n",
    "        x_inter_preds = inter_preds\n",
    "\n",
    "    pred_adata = adata_inter.copy()\n",
    "    pred_adata.X = x_inter_preds\n",
    "    pred_adata.obs['ident'] = 'intervened on'\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        pred_adata.obsm[obsm_key] = inter_preds\n",
    "    return pred_adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8c3a1",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b5188",
   "metadata": {},
   "source": [
    "## Proccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc78e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "import sklearn.decomposition\n",
    "\n",
    "\n",
    "print(\"Loading and preprocessing data...\")\n",
    "adata = ad.read_h5ad(DATA_PATH)\n",
    "\n",
    "# adata.obs['L2_stim'] = [l1_ctype + '_' + stim for l1_ctype, stim in zip(adata.obs['cell_types_L2'], adata.obs['stim'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7015228e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>41BBL</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>APRIL</th>\n",
       "      <th>BAFF</th>\n",
       "      <th>C3a</th>\n",
       "      <th>C5a</th>\n",
       "      <th>Cardiotrophin-1</th>\n",
       "      <th>CD27L</th>\n",
       "      <th>CD30L</th>\n",
       "      <th>CD40L</th>\n",
       "      <th>...</th>\n",
       "      <th>MigDC</th>\n",
       "      <th>Monocyte</th>\n",
       "      <th>Neutrophil</th>\n",
       "      <th>NK_cell</th>\n",
       "      <th>pDC</th>\n",
       "      <th>T_cell_CD4</th>\n",
       "      <th>T_cell_CD8</th>\n",
       "      <th>T_cell_gd</th>\n",
       "      <th>T_cell_Ki67</th>\n",
       "      <th>Treg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CATAGACGTAACGATA-18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGTGAATCAGCGAGTA-10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGGTCGGTAACCCTA-10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACTTTGTGTACGAGTG-42</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTGTAACCATGACTTG-18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATACTTGTAGTCACT-40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGAACCCAGACATAAC-40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATGGGAGGTAAGATTG-44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATGGATCCAGTCGGAA-40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCGTTCACATGTGTCA-40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110378 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     41BBL  Adiponectin  APRIL  BAFF  C3a  C5a  \\\n",
       "CATAGACGTAACGATA-18      1            0      0     0    0    0   \n",
       "CGTGAATCAGCGAGTA-10      1            0      0     0    0    0   \n",
       "ACGGTCGGTAACCCTA-10      1            0      0     0    0    0   \n",
       "ACTTTGTGTACGAGTG-42      1            0      0     0    0    0   \n",
       "GTGTAACCATGACTTG-18      1            0      0     0    0    0   \n",
       "...                    ...          ...    ...   ...  ...  ...   \n",
       "CATACTTGTAGTCACT-40      0            0      0     0    0    0   \n",
       "GGAACCCAGACATAAC-40      0            0      0     0    0    0   \n",
       "ATGGGAGGTAAGATTG-44      0            0      0     0    0    0   \n",
       "ATGGATCCAGTCGGAA-40      0            0      0     0    0    0   \n",
       "CCGTTCACATGTGTCA-40      0            0      0     0    0    0   \n",
       "\n",
       "                     Cardiotrophin-1  CD27L  CD30L  CD40L  ...  MigDC  \\\n",
       "CATAGACGTAACGATA-18                0      0      0      0  ...      0   \n",
       "CGTGAATCAGCGAGTA-10                0      0      0      0  ...      0   \n",
       "ACGGTCGGTAACCCTA-10                0      0      0      0  ...      0   \n",
       "ACTTTGTGTACGAGTG-42                0      0      0      0  ...      0   \n",
       "GTGTAACCATGACTTG-18                0      0      0      0  ...      0   \n",
       "...                              ...    ...    ...    ...  ...    ...   \n",
       "CATACTTGTAGTCACT-40                0      0      0      0  ...      0   \n",
       "GGAACCCAGACATAAC-40                0      0      0      0  ...      0   \n",
       "ATGGGAGGTAAGATTG-44                0      0      0      0  ...      0   \n",
       "ATGGATCCAGTCGGAA-40                0      0      0      0  ...      0   \n",
       "CCGTTCACATGTGTCA-40                0      0      0      0  ...      0   \n",
       "\n",
       "                     Monocyte  Neutrophil  NK_cell  pDC  T_cell_CD4  \\\n",
       "CATAGACGTAACGATA-18         0           0        0    0           0   \n",
       "CGTGAATCAGCGAGTA-10         0           0        0    0           0   \n",
       "ACGGTCGGTAACCCTA-10         0           0        0    0           0   \n",
       "ACTTTGTGTACGAGTG-42         0           0        0    0           0   \n",
       "GTGTAACCATGACTTG-18         0           0        0    0           0   \n",
       "...                       ...         ...      ...  ...         ...   \n",
       "CATACTTGTAGTCACT-40         0           0        0    0           0   \n",
       "GGAACCCAGACATAAC-40         0           0        0    0           0   \n",
       "ATGGGAGGTAAGATTG-44         0           0        0    0           0   \n",
       "ATGGATCCAGTCGGAA-40         0           0        0    0           0   \n",
       "CCGTTCACATGTGTCA-40         0           0        0    0           0   \n",
       "\n",
       "                     T_cell_CD8  T_cell_gd  T_cell_Ki67  Treg  \n",
       "CATAGACGTAACGATA-18           0          0            0     0  \n",
       "CGTGAATCAGCGAGTA-10           0          0            0     0  \n",
       "ACGGTCGGTAACCCTA-10           0          0            0     0  \n",
       "ACTTTGTGTACGAGTG-42           0          0            0     0  \n",
       "GTGTAACCATGACTTG-18           0          0            0     0  \n",
       "...                         ...        ...          ...   ...  \n",
       "CATACTTGTAGTCACT-40           0          0            0     1  \n",
       "GGAACCCAGACATAAC-40           0          0            0     1  \n",
       "ATGGGAGGTAAGATTG-44           0          0            0     1  \n",
       "ATGGATCCAGTCGGAA-40           0          0            0     1  \n",
       "CCGTTCACATGTGTCA-40           0          0            0     1  \n",
       "\n",
       "[110378 rows x 108 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obsm['concepts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5560ddfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Unable to synchronously create file (unable to open file: name = '/braid/havivd/immune_dictionary/lig_seurat_with_concepts_v2.h5ad', errno = 13, error message = 'Permission denied', flags = 13, o_flags = 242)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43madata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_h5ad\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/braid/havivd/immune_dictionary/lig_seurat_with_concepts_v2.h5ad\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/conceptlab/.venv/lib/python3.11/site-packages/legacy_api_wrap/__init__.py:82\u001b[39m, in \u001b[36mlegacy_api.<locals>.wrapper.<locals>.fn_compatible\u001b[39m\u001b[34m(*args_all, **kw)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfn_compatible\u001b[39m(*args_all: P.args, **kw: P.kwargs) -> R:\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args_all) <= n_positional:\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     args_pos: P.args\n\u001b[32m     85\u001b[39m     args_pos, args_rest = args_all[:n_positional], args_all[n_positional:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/conceptlab/.venv/lib/python3.11/site-packages/anndata/_core/anndata.py:1902\u001b[39m, in \u001b[36mAnnData.write_h5ad\u001b[39m\u001b[34m(self, filename, convert_strings_to_categoricals, compression, compression_opts, as_dense)\u001b[39m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     filename = \u001b[38;5;28mself\u001b[39m.filename\n\u001b[32m-> \u001b[39m\u001b[32m1902\u001b[39m \u001b[43mwrite_h5ad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1903\u001b[39m \u001b[43m    \u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1904\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconvert_strings_to_categoricals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_strings_to_categoricals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_dense\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_dense\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1909\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1911\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.isbacked:\n\u001b[32m   1912\u001b[39m     \u001b[38;5;28mself\u001b[39m.file.filename = filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/conceptlab/.venv/lib/python3.11/site-packages/anndata/_io/utils.py:325\u001b[39m, in \u001b[36mno_write_dataset_2d.<locals>.raise_error_if_dataset_2d_present\u001b[39m\u001b[34m(store, adata, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m     msg = (\n\u001b[32m    319\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWriting AnnData objects with a Dataset2D not supported yet. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    320\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease use `ds.to_memory` to bring the dataset into memory. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNote that if you have generated this object by concatenating several `AnnData` objects\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe original types may be lost.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/conceptlab/.venv/lib/python3.11/site-packages/anndata/_io/h5ad.py:82\u001b[39m, in \u001b[36mwrite_h5ad\u001b[39m\u001b[34m(filepath, adata, as_dense, convert_strings_to_categoricals, dataset_kwargs, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m adata.isbacked:  \u001b[38;5;66;03m# close so that we can reopen below\u001b[39;00m\n\u001b[32m     80\u001b[39m     adata.file.close()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mh5py\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# TODO: Use spec writing system for this\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;66;03m# Currently can't use write_dispatched here because this function is also called to do an\u001b[39;00m\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# inplace update of a backed object, which would delete \"/\"\u001b[39;00m\n\u001b[32m     86\u001b[39m     f = cast(\u001b[33m\"\u001b[39m\u001b[33mh5py.Group\u001b[39m\u001b[33m\"\u001b[39m, f[\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     87\u001b[39m     f.attrs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mencoding-type\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33manndata\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/conceptlab/.venv/lib/python3.11/site-packages/h5py/_hl/files.py:564\u001b[39m, in \u001b[36mFile.__init__\u001b[39m\u001b[34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[39m\n\u001b[32m    555\u001b[39m     fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[32m    556\u001b[39m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[32m    557\u001b[39m                      alignment_threshold=alignment_threshold,\n\u001b[32m    558\u001b[39m                      alignment_interval=alignment_interval,\n\u001b[32m    559\u001b[39m                      meta_block_size=meta_block_size,\n\u001b[32m    560\u001b[39m                      **kwds)\n\u001b[32m    561\u001b[39m     fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[32m    562\u001b[39m                      fs_persist=fs_persist, fs_threshold=fs_threshold,\n\u001b[32m    563\u001b[39m                      fs_page_size=fs_page_size)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     fid = \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    567\u001b[39m     \u001b[38;5;28mself\u001b[39m._libver = libver\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/conceptlab/.venv/lib/python3.11/site-packages/h5py/_hl/files.py:244\u001b[39m, in \u001b[36mmake_fid\u001b[39m\u001b[34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[39m\n\u001b[32m    242\u001b[39m     fid = h5f.create(name, h5f.ACC_EXCL, fapl=fapl, fcpl=fcpl)\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     fid = \u001b[43mh5f\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh5f\u001b[49m\u001b[43m.\u001b[49m\u001b[43mACC_TRUNC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    246\u001b[39m     \u001b[38;5;66;03m# Open in append mode (read/write).\u001b[39;00m\n\u001b[32m    247\u001b[39m     \u001b[38;5;66;03m# If that fails, create a new file only if it won't clobber an\u001b[39;00m\n\u001b[32m    248\u001b[39m     \u001b[38;5;66;03m# existing one (ACC_EXCL)\u001b[39;00m\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:56\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/_objects.pyx:57\u001b[39m, in \u001b[36mh5py._objects.with_phil.wrapper\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mh5py/h5f.pyx:122\u001b[39m, in \u001b[36mh5py.h5f.create\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Unable to synchronously create file (unable to open file: name = '/braid/havivd/immune_dictionary/lig_seurat_with_concepts_v2.h5ad', errno = 13, error message = 'Permission denied', flags = 13, o_flags = 242)"
     ]
    }
   ],
   "source": [
    "adata.write_h5ad('/braid/havivd/immune_dictionary/lig_seurat_with_concepts_v2.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23aae77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotting Configuration ---\n",
    "CT_CMAP = {'B_cell': '#1f77b3',\n",
    " 'Basophil': '#ff7e0e',\n",
    " 'FRC': '#2ba02b',\n",
    " 'ILC': '#d62628',\n",
    " 'LEC': '#9367bc',\n",
    " 'Langerhans': '#8c564b',\n",
    " 'Macrophage': '#e277c1',\n",
    " 'Mast_cell': '#7e7e7e',\n",
    " 'MigDC': '#bcbc21',\n",
    " 'Monocyte': '#16bdcf',\n",
    " 'NK_cell': '#3a0182',\n",
    " 'Neutrophil': '#004201',\n",
    " 'T_cell_CD4': '#0fffa8',\n",
    " 'T_cell_CD8': '#5d003f',\n",
    " 'T_cell_Ki67': '#bcbcff',\n",
    " 'T_cell_gd': '#d8afa1',\n",
    " 'Treg': '#b80080',\n",
    " 'cDC1': '#004d52',\n",
    " 'cDC2': '#6b6400',\n",
    " 'eTAC': '#7c0100',\n",
    " 'pDC': '#6026ff'}\n",
    "\n",
    "STIM_CMAP = {'ctrl': '#b80080', 'stim': '#e277c1', 'other': '#7e7e7e'}\n",
    "# IDENT_CMAP = {\n",
    "#     'train': '#676765', 'held out for intervention': '#c84639',\n",
    "#     'held out as GT': '#048757', 'intervened on': '#06d400'\n",
    "# }\n",
    "\n",
    "IDENT_CMAP = {\n",
    "    'train': '#676765', 'intervention': '#c84639','held out for intervention': '#c84639',\n",
    "    'held out as GT': '#048757', 'intervened on': '#06d400'\n",
    "}\n",
    "\n",
    "TITLE_MAP = {'celltype': 'Cell Type', 'stim': 'State', 'ident': 'Split'}\n",
    "\n",
    "\n",
    "cell_type_clusters = {\n",
    "    # Lymphoid cells are crucial for the adaptive immune response.\n",
    "    'Lymphoid': {\n",
    "        'T_cell': [\n",
    "            'T_cell_CD4',\n",
    "            'T_cell_CD8',\n",
    "            'T_cell_Ki67',\n",
    "            'T_cell_gd',\n",
    "            'Treg'\n",
    "        ],\n",
    "        'B_cell': [\n",
    "            'B_cell'\n",
    "        ],\n",
    "        'Innate_lymphoid_cell': [\n",
    "            'ILC',\n",
    "            'NK_cell'\n",
    "        ]\n",
    "    },\n",
    "    # Myeloid cells are primarily part of the innate immune system.\n",
    "    'Myeloid': {\n",
    "        'Dendritic_cell': [\n",
    "            'cDC1',\n",
    "            'cDC2',\n",
    "            'Langerhans',\n",
    "            'MigDC',\n",
    "            'pDC'\n",
    "        ],\n",
    "        'Monocyte_Macrophage': [\n",
    "            'Macrophage',\n",
    "            'Monocyte'\n",
    "        ],\n",
    "        'Granulocyte': [\n",
    "            'Basophil',\n",
    "            'Mast_cell',\n",
    "            'Neutrophil'\n",
    "        ]\n",
    "    },\n",
    "    # Stromal cells provide structure and support within tissues.\n",
    "    'Stromal_Other': {\n",
    "        'Stromal': [\n",
    "            'FRC',\n",
    "            'LEC',\n",
    "            'eTAC'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Example of how to access a specific group:\n",
    "# print(cell_type_clusters['Myeloid']['Granulocyte'])\n",
    "\n",
    "# --- Look-Up Table (LUT) Generation ---\n",
    "\n",
    "# Create an LUT to map each specific subtype to its parent group (e.g., 'T_cell_CD4' -> 'T_cell').\n",
    "# This uses a dictionary comprehension to iterate through the nested structure.\n",
    "subtype_to_group_lut = {\n",
    "    subtype: group\n",
    "    for major_group, sub_groups in cell_type_clusters.items()\n",
    "    for group, subtypes in sub_groups.items()\n",
    "    for subtype in subtypes \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5205a8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['cell_type_L1'] = adata.obs['celltype'].map(subtype_to_group_lut)\n",
    "adata.obs['cell_type_L2'] = adata.obs['celltype']\n",
    "\n",
    "adata.obsm['concepts'] = pd.get_dummies(adata.obs[['sample', 'cell_type_L1']]).astype(np.float32)\n",
    "adata.obsm['concepts'].columns = [col.replace('sample_', '').replace('cell_type_L1_', '') for col in adata.obsm['concepts'].columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf5d9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['L1_stim'] = [ctype + \"_\" + stim for ctype, stim in zip(adata.obs['cell_type_L1'], adata.obs['sample'])]\n",
    "adata.obs['L2_stim'] = [ctype + \"_\" + stim for ctype, stim in zip(adata.obs['cell_type_L2'], adata.obs['sample'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e3c7027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B_cell',\n",
       " 'Basophil',\n",
       " 'FRC',\n",
       " 'ILC',\n",
       " 'LEC',\n",
       " 'Langerhans',\n",
       " 'Macrophage',\n",
       " 'Mast_cell',\n",
       " 'MigDC',\n",
       " 'Monocyte',\n",
       " 'NK_cell',\n",
       " 'Neutrophil',\n",
       " 'T_cell_CD4',\n",
       " 'T_cell_CD8',\n",
       " 'T_cell_Ki67',\n",
       " 'T_cell_gd',\n",
       " 'Treg',\n",
       " 'cDC1',\n",
       " 'cDC2',\n",
       " 'eTAC',\n",
       " 'pDC'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(adata.obs['cell_type_L2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfed101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val = adata.obs['L2_stim'].value_counts()\n",
    "\n",
    "# for ind in val.index:\n",
    "#     print(ind, val[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2601ebaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ef2cd87",
   "metadata": {},
   "source": [
    "# Run Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27191e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad('/braid/havivd/immune_dictionary/lig_seurat_with_concepts_v2.h5ad')\n",
    "pre_computed_mmd_train = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d16634f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Main Benchmark Across All Labels ---\n",
      "Splitting data with simplified logic...\n",
      "\n",
      "--- Processing Label: T_cell_CD4_TGF-beta-1 ---\n",
      "Train set: 110278 cells, Test set: 100 cells, Intervention set: 100 cells\n",
      "Training and Evaluating CBGM\n",
      "Training scCBGM model...\n",
      "Starting training on cuda for 200 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [17:12<00:00,  5.16s/it, avg_loss=1.318e-01, concept_f1=0.9828, lr=1.64990e-04]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n",
      "Performing intervention with scCBGM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pre_computed_mmd_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     83\u001b[39m all_names = [\u001b[33m'\u001b[39m\u001b[33mscCBGM\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pred_adata, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(all_models, all_names):\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# Check if the baseline MMD has been computed for this label yet\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpre_computed_mmd_train\u001b[49m == -\u001b[32m1\u001b[39m:\n\u001b[32m     87\u001b[39m         \u001b[38;5;66;03m# First run: compute everything and store the baseline MMD\u001b[39;00m\n\u001b[32m     88\u001b[39m         evaluation_output = clab.evaluation.interventions.evaluate_intervention_mmd_with_target(\n\u001b[32m     89\u001b[39m             x_train=adata_train.obsm[OBSM_KEY], \n\u001b[32m     90\u001b[39m             x_ivn=pred_adata.obsm[OBSM_KEY], \n\u001b[32m     91\u001b[39m             x_target=adata_test.obsm[OBSM_KEY],\n\u001b[32m     92\u001b[39m             labels_train=adata_train.obs[\u001b[33m'\u001b[39m\u001b[33mL1_stim\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m     93\u001b[39m         )\n\u001b[32m     94\u001b[39m         mmd_ratio = evaluation_output[\u001b[33m'\u001b[39m\u001b[33mmmd_ratio\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'pre_computed_mmd_train' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Results Storage Initialization ---\n",
    "benchmark_instances = [{'cell_type': 'T_cell_CD4', 'ctrl': 'PBS', 'stim': 'TGF-beta-1'},\n",
    "                       {'cell_type': 'T_cell_CD8', 'ctrl': 'PBS', 'stim': 'TNFa'},\n",
    "                       {'cell_type': 'T_cell_gd', 'ctrl': 'PBS', 'stim': 'IL17E'},\n",
    "                       {'cell_type': 'NK_cell', 'ctrl': 'PBS', 'stim': 'IL15'},\n",
    "                       {'cell_type': 'Macrophage', 'ctrl': 'PBS', 'stim': 'M-CSF'},\n",
    "                       {'cell_type': 'cDC2', 'ctrl': 'PBS', 'stim': 'IFNa1'},\n",
    "                       {'cell_type': 'Langerhans', 'ctrl': 'PBS', 'stim': 'IFNg'}]\n",
    "\n",
    "benchmark_results = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "\n",
    "\n",
    "## Main Benchmark Loop\n",
    "# =================================================================\n",
    "# In this loop, we evaluate all models with their default parameters\n",
    "# across all cell types to get a baseline performance comparison.\n",
    "# =================================================================\n",
    "\n",
    "print(\"--- Starting Main Benchmark Across All Labels ---\")\n",
    "for instance in benchmark_instances:\n",
    "\n",
    "    hold_out_label = instance['cell_type'] + '_' + instance['stim']\n",
    "    mod_label = instance['cell_type'] +'_' + instance['ctrl']\n",
    "\n",
    "    adata, adata_train, adata_test, adata_inter = split_data(\n",
    "        adata, hold_out_label, mod_label, label_key = 'L2_stim'\n",
    "    )\n",
    "\n",
    "    stim_index = np.where(adata.obsm['concepts'].columns == instance['stim'])[0][0]\n",
    "\n",
    "    ctrl_index = np.where(np.isin(adata.obsm['concepts'].columns, list(set(adata.obs['sample']))))[0]\n",
    "    ctrl_index = np.delete(ctrl_index, np.where(ctrl_index == stim_index)[0][0])\n",
    "\n",
    "    print(f\"\\n--- Processing Label: {hold_out_label} ---\")\n",
    "    print(f\"Train set: {len(adata_train)} cells, Test set: {len(adata_test)} cells, Intervention set: {len(adata_inter)} cells\")\n",
    "\n",
    "    # PCA Transformation\n",
    "    adata.uns['pc_transform'] = sklearn.decomposition.PCA(n_components=128).fit(adata_train.X)\n",
    "    for x_data in [adata, adata_train, adata_test, adata_inter]:\n",
    "        x_data.uns['pc_transform'] = adata.uns['pc_transform']\n",
    "        x_data.obsm['X_pca'] = x_data.uns['pc_transform'].transform(x_data.X)\n",
    "\n",
    "    # --- Train All Models ---\n",
    "\n",
    "    print(\"Training and Evaluating CBGM\")\n",
    "\n",
    "    cbgm_model = train_cbgm(adata_train.copy())\n",
    "    pred_adata_cbgm = pred_cbgm(cbgm_model, adata_inter.copy(), ctrl_index, stim_index)\n",
    "    \n",
    "    if False:\n",
    "\n",
    "        print(\"Training and Evaluating FM\")\n",
    "\n",
    "\n",
    "        adata_with_concepts = get_learned_concepts(cbgm_model, adata.copy())\n",
    "        adata_train.obsm['scCBGM_concepts'] = adata_with_concepts[adata_train.obs.index].obsm['scCBGM_concepts']\n",
    "        adata_inter.obsm['scCBGM_concepts'] = adata_with_concepts[adata_inter.obs.index].obsm['scCBGM_concepts']\n",
    "\n",
    "        \n",
    "        cb_fm_model = train_cb_fm(adata_train.copy())\n",
    "        pred_adata_fm_edit = pred_cb_fm(cb_fm_model, adata_inter.copy(), ctrl_index, stim_index, edit = True)\n",
    "        pred_adata_fm_guid = pred_cb_fm(cb_fm_model, adata_inter.copy(), ctrl_index, stim_index, edit = False)\n",
    "\n",
    "        print(\"Training and Evaluating Raw FM\")\n",
    "        \n",
    "        fm_raw_model = train_raw_fm(adata_train.copy())\n",
    "        pred_adata_raw_fm_edit = pred_raw_fm(fm_raw_model, adata_inter.copy(), ctrl_index, stim_index, edit = True)\n",
    "        pred_adata_raw_fm_guid = pred_raw_fm(fm_raw_model, adata_inter.copy(), ctrl_index, stim_index, edit = False)\n",
    "\n",
    "        print(\"Training and Evaluating Concept Flow VAE\")\n",
    "\n",
    "        # Train VAE model with default hyperparameters\n",
    "        cb_fm_vae_model = train_cb_fm_vae(adata_train.copy(), kl_hp = 0.1, concepts_hp = 0.2, orthogonality_hp = 0.5)\n",
    "        pred_adata_cb_fm_vae = pred_cb_fm_vae(cb_fm_vae_model, adata_inter.copy(), ctrl_index, stim_index)\n",
    "\n",
    "        # --- Benchmark All Models for this Label ---\n",
    "        pre_computed_mmd_train = -1\n",
    "        all_models = [pred_adata_cbgm, pred_adata_fm_edit, pred_adata_fm_guid, pred_adata_raw_fm_edit,  pred_adata_raw_fm_guid, pred_adata_cb_fm_vae]\n",
    "        all_names = ['scCBGM', 'CB-FM (edit)', 'CB-FM (guided)', 'Raw-FM (edit)', 'Raw-FM (guided)', 'CB-FM (VAE)']\n",
    "\n",
    "    all_models  = [pred_adata_cbgm]\n",
    "    all_names = ['scCBGM']\n",
    "    for pred_adata, name in zip(all_models, all_names):\n",
    "        # Check if the baseline MMD has been computed for this label yet\n",
    "        if pre_computed_mmd_train == -1:\n",
    "            # First run: compute everything and store the baseline MMD\n",
    "            evaluation_output = clab.evaluation.interventions.evaluate_intervention_mmd_with_target(\n",
    "                x_train=adata_train.obsm[OBSM_KEY], \n",
    "                x_ivn=pred_adata.obsm[OBSM_KEY], \n",
    "                x_target=adata_test.obsm[OBSM_KEY],\n",
    "                labels_train=adata_train.obs['L1_stim'].values\n",
    "            )\n",
    "            mmd_ratio = evaluation_output['mmd_ratio']\n",
    "            pre_computed_mmd_train = evaluation_output['pre_computed_mmd_train']\n",
    "        else:\n",
    "            # Subsequent runs: provide the pre-computed baseline MMD to save time\n",
    "            evaluation_output = clab.evaluation.interventions.evaluate_intervention_mmd_with_target(\n",
    "                x_train=adata_train.obsm[OBSM_KEY], \n",
    "                x_ivn=pred_adata.obsm[OBSM_KEY], \n",
    "                x_target=adata_test.obsm[OBSM_KEY],\n",
    "                labels_train=adata_train.obs['L1_stim'].values,\n",
    "                pre_computed_mmd_train=pre_computed_mmd_train\n",
    "            )\n",
    "            mmd_ratio = evaluation_output['mmd_ratio']\n",
    "\n",
    "        # Now, calculate true MMD and store results\n",
    "        true_mmd = mmd_ratio * pre_computed_mmd_train\n",
    "        \n",
    "        benchmark_results[name]['mmd_ratio'].append(mmd_ratio)\n",
    "        benchmark_results[name]['true_mmd'].append(true_mmd)\n",
    "        print(f\"  > {name}: mmd_ratio={mmd_ratio:.4f}\")\n",
    "    break\n",
    "\n",
    "print(\"\\n--- Main Benchmark Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "996256fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_pca'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OBSM_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60496313",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_output = clab.evaluation.interventions.evaluate_intervention_mmd_with_target(\n",
    "                x_train=adata_train.obsm[OBSM_KEY], \n",
    "                x_ivn=pred_adata.obsm[OBSM_KEY], \n",
    "                x_target=adata_test.obsm[OBSM_KEY],\n",
    "                labels_train=adata_train.obs['L1_stim'].values\n",
    "            )\n",
    "mmd_ratio = evaluation_output['mmd_ratio']\n",
    "pre_computed_mmd_train = evaluation_output['pre_computed_mmd_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "135fd59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.04249617999621818)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192f62ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f\"{instance['cell_type']}\\n{instance['ctrl']}->{instance['stim']}\" for instance in benchmark_instances[:len(benchmark_results['scCBGM']['mmd_ratio'])]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8902854",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_form_data = []\n",
    "for model_name, metrics in benchmark_results.items():\n",
    "    # Ensure the number of scores matches the number of labels for robustness\n",
    "    if len(metrics.get('true_mmd', [])) != len(labels):\n",
    "        print(f\"Warning: Mismatch between score count and label count for model '{model_name}'. Skipping.\")\n",
    "        continue\n",
    "        \n",
    "    for i, label in enumerate(labels):\n",
    "        long_form_data.append({\n",
    "            'label': label,\n",
    "            'model': model_name,\n",
    "            'true_mmd': metrics['true_mmd'][i],\n",
    "            'mmd_ratio': metrics['mmd_ratio'][i]\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(long_form_data)\n",
    "\n",
    "\n",
    "# --- 2. Create Plots ---\n",
    "fig, ax = plt.subplots(1, 1, figsize=(24, 12)) # Adjusted figsize for a single plot\n",
    "\n",
    "sorted_labels = sorted(list(set(labels)))\n",
    "\n",
    "# --- Plot MMD Ratio, ensuring the x-axis is sorted ---\n",
    "sns.barplot(data=df, x='label', y='mmd_ratio', hue='model', ax=ax, order=sorted_labels)\n",
    "\n",
    "# --- SET Y-AXIS TO LOG SCALE ---\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_ylabel('MMD Ratio (Log Scale, Lower is Better)', fontsize=14)\n",
    "ax.set_xlabel('Cell Type', fontsize=14)\n",
    "ax.set_title('Normalized Prediction Error (MMD Ratio)', fontsize=18)\n",
    "\n",
    "# Format x-tick labels to be on two lines based on the sorted list\n",
    "# new_labels = [label.replace('_', '\\n') for label in sorted_labels]\n",
    "# new_labels = [label.replace('Monocytes', 'Mono') for label in new_labels]\n",
    "# new_labels = [label.replace('cells', '') for label in new_labels]\n",
    "ax.set_xticklabels(sorted_labels, fontsize=12)\n",
    "\n",
    "ax.legend(title='Model', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "# Adjust layout to make space for the external legend and the main title\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb9ca61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conceptlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
