{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a3286f",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225a171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2a14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afbd528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conceptlab as clab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import scipy.spatial\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "import string\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c17dc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd1a11a8cb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH  = '/braid/havivd/liver_doses/SCP1871/adata_liver.h5ad'\n",
    "OBSM_KEY = 'X_pca'\n",
    "Z_SCORE = False\n",
    "HARD_CONCEPT_KEY = 'hard_concepts'\n",
    "SOFT_CONCEPT_KEY = 'soft_concepts'\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd7a90c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8898b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['seurat_clusters', 'biosample_id', 'donor_id', 'CellID', 'disease',\n",
       "       'disease__ontology_label', 'species', 'species__ontology_label',\n",
       "       'organ', 'organ__ontology_label',\n",
       "       ...\n",
       "       'cell_type__ontology_label', 'cell_type', 'cell_type_dose',\n",
       "       'cell_type_treatment', 'HEP_ControlOnly_cluster', 'Y', 'cell_types_L2',\n",
       "       'cell_types_L1', 'L1_dose', 'L2_dose'],\n",
       "      dtype='object', length=109)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b091b0b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_types_L1_Cholangiocyte</th>\n",
       "      <th>cell_types_L1_Hepatocyte</th>\n",
       "      <th>cell_types_L1_Immune Cell</th>\n",
       "      <th>cell_types_L1_Stromal Cell</th>\n",
       "      <th>dose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAACCCACAACTTCTT_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCACAGTTAGGG_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCAGTGCCTGCA_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACCCATCACTGATG_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAACGAAAGGTACAAT_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGCACTTGGGC_24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGGTATCGCTA_24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGGTATGCAAA_24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCCCGTTGT_24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTTGTTGTCTCTGAGA_24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131613 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     cell_types_L1_Cholangiocyte  cell_types_L1_Hepatocyte  \\\n",
       "AAACCCACAACTTCTT_1                           0.0                       0.0   \n",
       "AAACCCACAGTTAGGG_1                           0.0                       1.0   \n",
       "AAACCCAGTGCCTGCA_1                           0.0                       1.0   \n",
       "AAACCCATCACTGATG_1                           0.0                       0.0   \n",
       "AAACGAAAGGTACAAT_1                           0.0                       0.0   \n",
       "...                                          ...                       ...   \n",
       "TTTGTTGCACTTGGGC_24                          0.0                       0.0   \n",
       "TTTGTTGGTATCGCTA_24                          0.0                       0.0   \n",
       "TTTGTTGGTATGCAAA_24                          0.0                       0.0   \n",
       "TTTGTTGTCCCGTTGT_24                          0.0                       0.0   \n",
       "TTTGTTGTCTCTGAGA_24                          1.0                       0.0   \n",
       "\n",
       "                     cell_types_L1_Immune Cell  cell_types_L1_Stromal Cell  \\\n",
       "AAACCCACAACTTCTT_1                         0.0                         1.0   \n",
       "AAACCCACAGTTAGGG_1                         0.0                         0.0   \n",
       "AAACCCAGTGCCTGCA_1                         0.0                         0.0   \n",
       "AAACCCATCACTGATG_1                         0.0                         1.0   \n",
       "AAACGAAAGGTACAAT_1                         0.0                         1.0   \n",
       "...                                        ...                         ...   \n",
       "TTTGTTGCACTTGGGC_24                        1.0                         0.0   \n",
       "TTTGTTGGTATCGCTA_24                        0.0                         1.0   \n",
       "TTTGTTGGTATGCAAA_24                        1.0                         0.0   \n",
       "TTTGTTGTCCCGTTGT_24                        1.0                         0.0   \n",
       "TTTGTTGTCTCTGAGA_24                        0.0                         0.0   \n",
       "\n",
       "                     dose  \n",
       "AAACCCACAACTTCTT_1    0.0  \n",
       "AAACCCACAGTTAGGG_1    0.0  \n",
       "AAACCCAGTGCCTGCA_1    0.0  \n",
       "AAACCCATCACTGATG_1    0.0  \n",
       "AAACGAAAGGTACAAT_1    0.0  \n",
       "...                   ...  \n",
       "TTTGTTGCACTTGGGC_24   1.0  \n",
       "TTTGTTGGTATCGCTA_24   1.0  \n",
       "TTTGTTGGTATGCAAA_24   1.0  \n",
       "TTTGTTGTCCCGTTGT_24   1.0  \n",
       "TTTGTTGTCTCTGAGA_24   1.0  \n",
       "\n",
       "[131613 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obsm[\"concepts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c8ba31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hepatic stellate cell', 'periportal region hepatocyte', 'endothelial cell of hepatic sinusoid', 'cholangiocyte', 'macrophage', ..., 'B cell', 'T cell', 'hepatic portal fibroblast', 'neutrophil', 'liver dendritic cell']\n",
       "Length: 11\n",
       "Categories (11, object): ['B cell', 'T cell', 'centrilobular region hepatocyte', 'cholangiocyte', ..., 'liver dendritic cell', 'macrophage', 'neutrophil', 'periportal region hepatocyte']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs[\"cell_types_L2\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1da2c3",
   "metadata": {},
   "source": [
    "# DATA LOADING AND PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f65d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(adata, hold_out_label, mod_label, label_key = 'L2_stim'):\n",
    "    \"\"\"\n",
    "    Splits data into train, intervention, and ground truth sets.\n",
    "\n",
    "    - Ground Truth: All cells with the `hold_out_label`.\n",
    "    - Intervention: All cells with the `mod_label`.\n",
    "    - Train: All remaining cells.\n",
    "    \"\"\"\n",
    "    \n",
    "    # if held out label is not a list, make it one\n",
    "    if not isinstance(hold_out_label, list):\n",
    "        hold_out_label = [hold_out_label]\n",
    "\n",
    "    print(\"Splitting data with simplified logic...\")\n",
    "    labels = adata.obs[label_key]\n",
    "\n",
    "    # Define the three disjoint sets based on their labels\n",
    "    is_test = np.isin(labels, hold_out_label)\n",
    "    is_inter = (labels == mod_label)\n",
    "    is_train = ~is_test\n",
    "\n",
    "    # Create AnnData objects for each split\n",
    "    adata_train = adata[is_train].copy()\n",
    "    adata_test = adata[is_test].copy()\n",
    "    adata_inter = adata[is_inter].copy()\n",
    "\n",
    "    # Store split identifiers in the original object\n",
    "    ident_vec = np.array(['train'] * len(adata)).astype('<U32')\n",
    "    ident_vec[is_test] = 'held out as GT'\n",
    "    ident_vec[is_inter] = 'intervention'\n",
    "    adata.obs['ident'] = ident_vec\n",
    "    \n",
    "\n",
    "    return adata, adata_train, adata_test, adata_inter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce377a4a",
   "metadata": {},
   "source": [
    "# MODELING & PREDICTION METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8637333d",
   "metadata": {},
   "source": [
    "## Method 1: scCBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "117fa200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cbgm(adata_train, obsm_key='X_pca', hard_concept_key=None, soft_concept_key=None):\n",
    "    \"\"\"\n",
    "    Trains and returns the scCBGM model, supporting separate hard and soft concepts.\n",
    "    \"\"\"\n",
    "    print(\"Training scCBGM model...\")\n",
    "\n",
    "    # --- Data Source Setup ---\n",
    "    if obsm_key != 'X':\n",
    "        data_matrix = adata_train.obsm[obsm_key]\n",
    "    else:\n",
    "        data_matrix = adata_train.X\n",
    "    \n",
    "    # --- Input Validation ---\n",
    "    if hard_concept_key is None and soft_concept_key is None:\n",
    "        raise ValueError(\"You must provide at least one of 'hard_concept_key' or 'soft_concept_key'.\")\n",
    "\n",
    "    torch.set_flush_denormal(True)\n",
    "\n",
    "    # --- Prepare Concept Tensors ---\n",
    "    hard_concepts_tensor = None\n",
    "    n_hard = 0\n",
    "    if hard_concept_key:\n",
    "        hard_concepts_data = adata_train.obsm[hard_concept_key].to_numpy().astype(np.float32)\n",
    "        hard_concepts_tensor = torch.from_numpy(hard_concepts_data)\n",
    "        n_hard = hard_concepts_tensor.shape[1]\n",
    "\n",
    "    soft_concepts_tensor = None\n",
    "    n_soft = 0\n",
    "    if soft_concept_key:\n",
    "        soft_concepts_data = adata_train.obsm[soft_concept_key].to_numpy().astype(np.float32)\n",
    "        soft_concepts_tensor = torch.from_numpy(soft_concepts_data)\n",
    "        n_soft = soft_concepts_tensor.shape[1]\n",
    "        \n",
    "    # --- Dynamic Configuration ---\n",
    "    # This config now uses the new, more explicit keys.\n",
    "    config = OmegaConf.create(dict(\n",
    "        has_cbm=True, \n",
    "        lr=5e-4, \n",
    "        hidden_dim=1024, \n",
    "        n_layers=4,\n",
    "        beta=1e-5,\n",
    "        input_dim=data_matrix.shape[-1],\n",
    "        latent_dim=128,\n",
    "        # NEW: Explicitly define hard/soft concepts\n",
    "        use_hard_concepts=(hard_concept_key is not None),\n",
    "        n_hard_concepts=n_hard,\n",
    "        use_soft_concepts=(soft_concept_key is not None),\n",
    "        n_soft_concepts=n_soft,\n",
    "        n_unknown=128, \n",
    "        concepts_hp=0.1, \n",
    "        orthogonality_hp=0.5\n",
    "    ))\n",
    "    \n",
    "    # This assumes 'clab.models.scCBGM' points to the updated class in the Canvas\n",
    "    model = clab.models.CB_VAE_MIXED(config) \n",
    "    \n",
    "    # Since we can't import, we'll just print a placeholder for the model call\n",
    "    # print(\"Model would be initialized with config:\")\n",
    "    # print(OmegaConf.to_yaml(config))\n",
    "    \n",
    "    print(\"\\nModel's train_loop would be called with:\")\n",
    "    print(f\"data shape: {data_matrix.shape}\")\n",
    "    if hard_concepts_tensor is not None:\n",
    "        print(f\"hard_concepts shape: {hard_concepts_tensor.shape}\")\n",
    "    if soft_concepts_tensor is not None:\n",
    "        print(f\"soft_concepts shape: {soft_concepts_tensor.shape}\")\n",
    "\n",
    "    # --- Model Training ---\n",
    "    # The train_loop call now uses the explicit arguments.\n",
    "    model.train_loop(\n",
    "        data=torch.from_numpy(data_matrix.astype(np.float32)),\n",
    "        hard_concepts=hard_concepts_tensor,\n",
    "        soft_concepts=soft_concepts_tensor,\n",
    "        num_epochs=200, \n",
    "        batch_size=128, \n",
    "        lr=3e-4,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def pred_cbgm(model, adata_inter, obsm_key='X_pca', hard_concept_key=None, soft_concept_key=None, interventions=None):\n",
    "    \"\"\"\n",
    "    Performs targeted intervention on specific concepts using a trained scCBGM model.\n",
    "\n",
    "    Args:\n",
    "        model: The trained scCBGM model.\n",
    "        adata_inter: AnnData object with data to perform intervention on.\n",
    "        obsm_key: Key in adata_inter.obsm to use as input, or 'X' for adata_inter.X.\n",
    "        hard_concept_key: Key in adata_inter.obsm for the hard concepts DataFrame.\n",
    "        soft_concept_key: Key in adata_inter.obsm for the soft concepts DataFrame.\n",
    "        interventions (dict): A dictionary specifying the interventions.\n",
    "                              Keys are concept column names.\n",
    "                              Values are the new target values for those concepts.\n",
    "                              Example: {'stim': 1, 'cell_cycle_G2M': 0.8}\n",
    "    \"\"\"\n",
    "    print(\"Performing intervention with scCBGM...\")\n",
    "\n",
    "    if interventions is None or not interventions:\n",
    "        print(\"No interventions specified. Returning a copy of the original data.\")\n",
    "        return adata_inter.copy()\n",
    "\n",
    "    # --- Get input data ---\n",
    "    x_intervene_on = torch.tensor(adata_inter.obsm[obsm_key] if obsm_key != 'X' else adata_inter.X, dtype=torch.float32)\n",
    "\n",
    "    # --- Prepare original concept tensors and find column indices ---\n",
    "    concept_parts, hard_concepts_df, soft_concepts_df = [], None, None\n",
    "    n_hard = 0\n",
    "\n",
    "    if hard_concept_key:\n",
    "        hard_concepts_df = adata_inter.obsm[hard_concept_key]\n",
    "        concept_parts.append(torch.from_numpy(hard_concepts_df.to_numpy(dtype=np.float32)))\n",
    "        n_hard = hard_concepts_df.shape[1]\n",
    "\n",
    "    if soft_concept_key:\n",
    "        soft_concepts_df = adata_inter.obsm[soft_concept_key]\n",
    "        concept_parts.append(torch.from_numpy(soft_concepts_df.to_numpy(dtype=np.float32)))\n",
    "\n",
    "    if not concept_parts:\n",
    "         raise ValueError(\"Must provide at least one concept key ('hard_concept_key' or 'soft_concept_key') to perform intervention.\")\n",
    "\n",
    "    c_intervene_on = torch.cat(concept_parts, dim=1)\n",
    "    inter_concepts = c_intervene_on.clone()\n",
    "    mask = torch.zeros_like(c_intervene_on)\n",
    "\n",
    "    # --- Build the mask and intervention tensor from the dictionary ---\n",
    "    for concept_name, new_value in interventions.items():\n",
    "        found = False\n",
    "        if hard_concepts_df is not None and concept_name in hard_concepts_df.columns:\n",
    "            col_idx = hard_concepts_df.columns.get_loc(concept_name)\n",
    "            mask[:, col_idx] = 1\n",
    "            inter_concepts[:, col_idx] = new_value\n",
    "            found = True\n",
    "            print(f\"Intervening on HARD concept '{concept_name}' (index {col_idx}) -> {new_value}\")\n",
    "\n",
    "        elif soft_concepts_df is not None and concept_name in soft_concepts_df.columns:\n",
    "            col_idx = soft_concepts_df.columns.get_loc(concept_name) + n_hard\n",
    "            mask[:, col_idx] = 1\n",
    "            inter_concepts[:, col_idx] = new_value\n",
    "            found = True\n",
    "            print(f\"Intervening on SOFT concept '{concept_name}' (index {col_idx}) -> {new_value}\")\n",
    "\n",
    "        if not found:\n",
    "            print(f\"Warning: Concept '{concept_name}' not found in provided keys. Ignoring.\")\n",
    "\n",
    "    # --- Run intervention on the model ---\n",
    "    device = 'cuda'\n",
    "    with torch.no_grad():\n",
    "        inter_preds_dict = model.intervene(x_intervene_on.to(device), mask=mask.to(device), concepts=inter_concepts.to(device))\n",
    "    inter_preds = inter_preds_dict['x_pred'].cpu().numpy()\n",
    "    \n",
    "\n",
    "    # --- Create prediction AnnData object ---\n",
    "    pred_adata = adata_inter.copy()\n",
    "\n",
    "    pred_adata.obs['ident'] = 'intervened'\n",
    "\n",
    "    if obsm_key != 'X':\n",
    "        pred_adata.X = np.zeros_like(pred_adata.X)\n",
    "        pred_adata.obsm[obsm_key] = inter_preds\n",
    "    else:\n",
    "        pred_adata.X = inter_preds\n",
    "\n",
    "    return pred_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec223ed8",
   "metadata": {},
   "source": [
    "##  Method 2: Flow Matching with Learned Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "640c4957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learned_concepts(scCBGM_model, adata_full, obsm_key = 'X_pca', hard_concept_key=None, soft_concept_key=None):\n",
    "    \"\"\"Uses a trained scCBGM to generate learned concepts for all data.\"\"\"\n",
    "    print(\"Generating learned concepts from scCBGM...\")\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        all_x = torch.tensor(adata_full.obsm[obsm_key], dtype=torch.float32).to('cuda')\n",
    "    else:\n",
    "        all_x = torch.tensor(adata_full.X, dtype=torch.float32).to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enc = scCBGM_model.encode(all_x)\n",
    "\n",
    "        if(scCBGM_model.use_hard_concepts):\n",
    "            scCBGM_concepts_known_hard = scCBGM_model.cb_hard_layers(enc['mu']).cpu().numpy()\n",
    "            scCBGM_concepts_known_hard_df = pd.DataFrame(scCBGM_concepts_known_hard, \n",
    "                                                         index=adata_full.obs.index, \n",
    "                                                         columns=adata_full.obsm[hard_concept_key].columns)\n",
    "        if(scCBGM_model.use_soft_concepts):\n",
    "            scCBGM_concepts_known_soft= scCBGM_model.cb_soft_layers(enc['mu']).cpu().numpy()\n",
    "            scCBGM_concepts_known_soft_df = pd.DataFrame(scCBGM_concepts_known_soft, \n",
    "                                                         index=adata_full.obs.index, \n",
    "                                                         columns=adata_full.obsm[soft_concept_key].columns)\n",
    "        \n",
    "        scCBGM_concepts_unknown = scCBGM_model.cb_unk_layers(enc['mu']).cpu().numpy()\n",
    "        scCBGM_concepts_unknown_df = pd.DataFrame(scCBGM_concepts_unknown, \n",
    "                                                 index=adata_full.obs.index, \n",
    "                                                 columns=[f'unknown_{i}' for i in range(scCBGM_concepts_unknown.shape[1])])\n",
    "    \n",
    "    if(scCBGM_model.use_hard_concepts and scCBGM_model.use_soft_concepts):\n",
    "        scCBGM_concepts = pd.concat([scCBGM_concepts_known_hard_df, scCBGM_concepts_known_soft_df, scCBGM_concepts_unknown_df], axis=1)\n",
    "    elif(scCBGM_model.use_hard_concepts):\n",
    "        scCBGM_concepts = pd.concat([scCBGM_concepts_known_hard_df, scCBGM_concepts_unknown_df], axis=1)\n",
    "    elif(scCBGM_model.use_soft_concepts):\n",
    "        scCBGM_concepts = pd.concat([scCBGM_concepts_known_soft_df, scCBGM_concepts_unknown_df], axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"Model has no known concepts to extract.\")\n",
    "    \n",
    "    adata_full.obsm['scCBGM_concepts'] = scCBGM_concepts\n",
    "\n",
    "\n",
    "    return adata_full\n",
    "\n",
    "def train_cb_fm(adata_train, concept_key = 'scCBGM_concepts', obsm_key = 'X_pca'):\n",
    "    \"\"\"Trains and returns the CB-FM model using learned concepts.\"\"\"\n",
    "    print(\"Training Concept Bottleneck Flow Model\")\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        data_matrix = adata_train.obsm[obsm_key]\n",
    "    else:\n",
    "        data_matrix = adata_train.X\n",
    "    \n",
    "    config = dict(\n",
    "        input_dim=data_matrix.shape[1],\n",
    "        hidden_dim=1024,\n",
    "        latent_dim=128,\n",
    "        n_concepts=adata_train.obsm[concept_key].shape[1],\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "        p_uncond = 0.0)\n",
    "\n",
    "    fm_model = clab.models.cond_fm.Cond_FM(config=config)\n",
    "\n",
    "    fm_model.train_loop(\n",
    "        data=torch.from_numpy(data_matrix.astype(np.float32)),\n",
    "        concepts=torch.from_numpy(adata_train.obsm[concept_key].to_numpy().astype(np.float32)),\n",
    "        num_epochs=200, batch_size=128, lr=3e-4,\n",
    "    )\n",
    "    return fm_model\n",
    "\n",
    "\n",
    "\n",
    "def pred_cb_fm(model, adata_inter, edit_concept, edit_value, concept_key = 'scCBGM_concepts', obsm_key = 'X_pca', edit = True):\n",
    "    \"\"\"Performs intervention using a trained learned-concept CB-FM model.\"\"\"\n",
    "    print(\"Performing intervention with CB-FM (learned)...\")\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        x_inter = adata_inter.obsm[obsm_key]\n",
    "    else:\n",
    "        x_inter = adata_inter.X\n",
    "    \n",
    "    init_concepts = adata_inter.obsm[concept_key]\n",
    "    edit_concepts = init_concepts.copy()\n",
    "\n",
    "    edit_concepts[edit_concept] = edit_value\n",
    "    # edit_concepts[:, -1] = 1 # Set stim concept to 1\n",
    "\n",
    "    init_concepts = init_concepts.to_numpy().astype(np.float32)\n",
    "    edit_concepts = edit_concepts.to_numpy().astype(np.float32)\n",
    "\n",
    "    if(edit):\n",
    "        inter_preds = model.edit(\n",
    "                x = torch.from_numpy(x_inter.astype(np.float32)).to('cuda'),\n",
    "                c = torch.from_numpy(init_concepts.astype(np.float32)).to('cuda'),\n",
    "                c_prime = torch.from_numpy(edit_concepts.astype(np.float32)).to('cuda'),\n",
    "                t_edit = 0.0,\n",
    "                n_steps = 1000,\n",
    "                w_cfg_forward = 1.0,\n",
    "                w_cfg_backward = 1.0,\n",
    "                noise_add = 0.0)\n",
    "    else:\n",
    "        inter_preds = model.decode(\n",
    "                h = torch.from_numpy(edit_concepts.astype(np.float32)).to('cuda'),\n",
    "                n_steps = 1000,\n",
    "                w_cfg = 1.0)\n",
    "        \n",
    "    inter_preds = inter_preds.detach().cpu().numpy()\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        x_inter_preds = np.zeros_like(adata_inter.X)\n",
    "    else:\n",
    "        x_inter_preds = inter_preds\n",
    "\n",
    "    pred_adata = adata_inter.copy()\n",
    "    pred_adata.X = x_inter_preds\n",
    "    pred_adata.obs['ident'] = 'intervened on'\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        pred_adata.obsm[obsm_key] = inter_preds\n",
    "    return pred_adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db46e42",
   "metadata": {},
   "source": [
    "## Method 3: Flow Matching with Raw Concepts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b6d9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_raw_fm(adata_train, concept_key = 'concepts', obsm_key = 'X_pca'):\n",
    "    \"\"\"Trains and returns the CB-FM model using learned concepts.\"\"\"\n",
    "    print(\"Training Conditonal Flow Model\")\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        data_matrix = adata_train.obsm[obsm_key]\n",
    "    else:\n",
    "        data_matrix = adata_train.X\n",
    "    \n",
    "    config = dict(\n",
    "        input_dim=data_matrix.shape[1],\n",
    "        hidden_dim=1024,\n",
    "        latent_dim=128,\n",
    "        n_concepts=adata_train.obsm[concept_key].to_numpy().shape[1],\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "        p_uncond = 0.0)\n",
    "\n",
    "    fm_model = clab.models.cond_fm.Cond_FM(config=config)\n",
    "\n",
    "    fm_model.train_loop(\n",
    "        data=torch.from_numpy(data_matrix.astype(np.float32)),\n",
    "        concepts=torch.from_numpy(adata_train.obsm[concept_key].to_numpy().astype(np.float32)),\n",
    "        num_epochs=200, batch_size=128, lr=3e-4,\n",
    "    )\n",
    "    return fm_model\n",
    "\n",
    "\n",
    "\n",
    "def pred_raw_fm(model, adata_inter, edit_concept, edit_value, concept_key = 'concepts', obsm_key = 'X_pca', edit = False):\n",
    "    \"\"\"Performs intervention using a trained learned-concept CB-FM model.\"\"\"\n",
    "    print(\"Performing intervention with Raw Flow Matching(learned)...\")\n",
    "\n",
    "    \n",
    "    if(obsm_key != 'X'):\n",
    "        x_inter = adata_inter.obsm[obsm_key]\n",
    "    else:\n",
    "        x_inter = adata_inter.X\n",
    "\n",
    "\n",
    "    init_concepts = adata_inter.obsm[concept_key]\n",
    "    edit_concepts = init_concepts.copy()\n",
    "\n",
    "    edit_concepts[edit_concept] = edit_value\n",
    "\n",
    "    init_concepts = init_concepts.to_numpy().astype(np.float32)\n",
    "    edit_concepts = edit_concepts.to_numpy().astype(np.float32)\n",
    "\n",
    "    if(edit):\n",
    "        inter_preds = model.edit(\n",
    "                x = torch.from_numpy(x_inter.astype(np.float32)).to('cuda'),\n",
    "                c = torch.from_numpy(init_concepts).to('cuda'),\n",
    "                c_prime = torch.from_numpy(edit_concepts).to('cuda'),\n",
    "                t_edit = 0.0,\n",
    "                n_steps = 1000,\n",
    "                w_cfg_forward = 1.0,\n",
    "                w_cfg_backward = 1.0,\n",
    "                noise_add = 0.0)\n",
    "    else:\n",
    "        inter_preds = model.decode(\n",
    "                h = torch.from_numpy(edit_concepts).to('cuda'),\n",
    "                n_steps = 1000,\n",
    "                w_cfg = 1.0)\n",
    "    \n",
    "    inter_preds = inter_preds.detach().cpu().numpy()\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        x_inter_preds = np.zeros_like(adata_inter.X)\n",
    "    else:\n",
    "        x_inter_preds = inter_preds\n",
    "\n",
    "    pred_adata = adata_inter.copy()\n",
    "    pred_adata.X = x_inter_preds\n",
    "    pred_adata.obs['ident'] = 'intervened on'\n",
    "\n",
    "    if(obsm_key != 'X'):\n",
    "        pred_adata.obsm[obsm_key] = inter_preds\n",
    "    return pred_adata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8c3a1",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b5188",
   "metadata": {},
   "source": [
    "## Proccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cc78e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d85ddf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading and preprocessing data...\")\n",
    "adata = ad.read_h5ad(DATA_PATH)\n",
    "adata.X = adata.X.toarray()\n",
    "# adata.X = adata.layers['raw'].toarray()\n",
    "# sc.pp.normalize_total(adata, target_sum=np.median(adata.X.sum(axis=1)))\n",
    "# sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes = 3000, subset=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9f619",
   "metadata": {},
   "source": [
    "### Create Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15d3db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_one_norm(x):\n",
    "    \"\"\"Normalizes a numpy array to the [0, 1] range.\"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    return (x - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d706473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_mapping = {\n",
    "    'centrilobular region hepatocyte': 'Hepatocyte',\n",
    "    'periportal region hepatocyte': 'Hepatocyte',\n",
    "    'B cell': 'Immune Cell',\n",
    "    'T cell': 'Immune Cell',\n",
    "    'liver dendritic cell': 'Immune Cell',\n",
    "    'macrophage': 'Immune Cell',\n",
    "    'neutrophil': 'Immune Cell',\n",
    "    'cholangiocyte': 'Cholangiocyte',\n",
    "    'endothelial cell of hepatic sinusoid': 'Stromal Cell',\n",
    "    'hepatic portal fibroblast': 'Stromal Cell',\n",
    "    'hepatic stellate cell': 'Stromal Cell'\n",
    "}\n",
    "\n",
    "adata.obs['cell_types_L2'] =  adata.obs['cell_type__ontology_label'].astype('category')\n",
    "adata.obs['cell_types_L1'] = adata.obs['cell_type__ontology_label'].map(cell_type_mapping).astype('category')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11af810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm[HARD_CONCEPT_KEY] = pd.get_dummies(adata.obs[['cell_types_L1']]).astype(np.float32)\n",
    "adata.obsm[SOFT_CONCEPT_KEY] = pd.DataFrame(zero_one_norm(np.log(adata.obs['dose'].astype(float).values + 1)).reshape(-1, 1),\n",
    "    index=adata.obs_names, columns=['dose']).astype(np.float32)\n",
    "\n",
    "adata.obsm['concepts'] = pd.concat([adata.obsm[HARD_CONCEPT_KEY], adata.obsm[SOFT_CONCEPT_KEY]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f65b25a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['L1_dose'] = [l1_ctype + '_' + dose for l1_ctype, dose in zip(adata.obs['cell_types_L1'], adata.obs['dose'])]\n",
    "adata.obs['L2_dose'] = [l2_ctype + '_' + dose for l2_ctype, dose in zip(adata.obs['cell_types_L2'], adata.obs['dose'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd724863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "periportal region hepatocyte_0.1: 9094\n",
      "periportal region hepatocyte_0.3: 8953\n",
      "periportal region hepatocyte_0.0: 7512\n",
      "periportal region hepatocyte_10.0: 6914\n",
      "periportal region hepatocyte_1.0: 6600\n",
      "periportal region hepatocyte_0.03: 6286\n",
      "macrophage_30.0: 6072\n",
      "periportal region hepatocyte_3.0: 5880\n",
      "periportal region hepatocyte_0.01: 4971\n",
      "centrilobular region hepatocyte_10.0: 3731\n",
      "centrilobular region hepatocyte_0.1: 2907\n",
      "endothelial cell of hepatic sinusoid_30.0: 2852\n",
      "centrilobular region hepatocyte_1.0: 2610\n",
      "centrilobular region hepatocyte_0.0: 2492\n",
      "centrilobular region hepatocyte_3.0: 2431\n",
      "macrophage_10.0: 2322\n",
      "centrilobular region hepatocyte_0.3: 2309\n",
      "endothelial cell of hepatic sinusoid_1.0: 2150\n",
      "endothelial cell of hepatic sinusoid_0.1: 2017\n",
      "endothelial cell of hepatic sinusoid_0.3: 1930\n",
      "endothelial cell of hepatic sinusoid_10.0: 1889\n",
      "macrophage_0.3: 1812\n",
      "centrilobular region hepatocyte_0.03: 1777\n",
      "macrophage_3.0: 1590\n",
      "B cell_30.0: 1565\n",
      "endothelial cell of hepatic sinusoid_0.03: 1518\n",
      "macrophage_0.0: 1508\n",
      "endothelial cell of hepatic sinusoid_0.0: 1495\n",
      "macrophage_1.0: 1490\n",
      "centrilobular region hepatocyte_0.01: 1485\n",
      "macrophage_0.1: 1467\n",
      "T cell_30.0: 1445\n",
      "centrilobular region hepatocyte_30.0: 1325\n",
      "endothelial cell of hepatic sinusoid_3.0: 1139\n",
      "hepatic stellate cell_0.3: 1136\n",
      "hepatic stellate cell_10.0: 1111\n",
      "periportal region hepatocyte_30.0: 1074\n",
      "hepatic stellate cell_0.1: 1051\n",
      "hepatic stellate cell_0.03: 951\n",
      "B cell_10.0: 861\n",
      "hepatic stellate cell_0.0: 849\n",
      "endothelial cell of hepatic sinusoid_0.01: 832\n",
      "hepatic stellate cell_1.0: 767\n",
      "T cell_10.0: 749\n",
      "macrophage_0.03: 723\n",
      "hepatic stellate cell_0.01: 621\n",
      "neutrophil_30.0: 614\n",
      "cholangiocyte_30.0: 600\n",
      "hepatic stellate cell_3.0: 553\n",
      "T cell_1.0: 457\n",
      "B cell_1.0: 435\n",
      "T cell_0.1: 395\n",
      "hepatic stellate cell_30.0: 391\n",
      "B cell_3.0: 323\n",
      "macrophage_0.01: 322\n",
      "T cell_3.0: 318\n",
      "B cell_0.1: 306\n",
      "B cell_0.3: 296\n",
      "liver dendritic cell_30.0: 280\n",
      "T cell_0.03: 277\n",
      "T cell_0.3: 271\n",
      "T cell_0.0: 242\n",
      "B cell_0.03: 221\n",
      "B cell_0.0: 208\n",
      "liver dendritic cell_10.0: 183\n",
      "T cell_0.01: 174\n",
      "cholangiocyte_10.0: 169\n",
      "cholangiocyte_0.1: 135\n",
      "cholangiocyte_0.3: 131\n",
      "B cell_0.01: 130\n",
      "neutrophil_10.0: 117\n",
      "cholangiocyte_0.0: 109\n",
      "hepatic portal fibroblast_3.0: 95\n",
      "hepatic portal fibroblast_0.03: 91\n",
      "hepatic portal fibroblast_0.1: 90\n",
      "hepatic portal fibroblast_0.0: 90\n",
      "cholangiocyte_0.03: 90\n",
      "liver dendritic cell_0.3: 87\n",
      "cholangiocyte_0.01: 87\n",
      "hepatic portal fibroblast_10.0: 85\n",
      "cholangiocyte_1.0: 80\n",
      "hepatic portal fibroblast_30.0: 76\n",
      "cholangiocyte_3.0: 70\n",
      "liver dendritic cell_0.0: 67\n",
      "neutrophil_0.0: 61\n",
      "liver dendritic cell_3.0: 61\n",
      "hepatic portal fibroblast_0.3: 60\n",
      "liver dendritic cell_1.0: 58\n",
      "liver dendritic cell_0.1: 55\n",
      "neutrophil_0.03: 54\n",
      "neutrophil_0.3: 48\n",
      "hepatic portal fibroblast_0.01: 47\n",
      "neutrophil_1.0: 46\n",
      "neutrophil_0.1: 38\n",
      "hepatic portal fibroblast_1.0: 37\n",
      "neutrophil_3.0: 37\n",
      "liver dendritic cell_0.03: 35\n",
      "liver dendritic cell_0.01: 28\n",
      "neutrophil_0.01: 20\n"
     ]
    }
   ],
   "source": [
    "value_counts = adata.obs['L2_dose'].value_counts()\n",
    "\n",
    "for index, count in value_counts.items():\n",
    "    print(f\"{index}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d25320",
   "metadata": {},
   "source": [
    "# Benchmark Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae936548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= Processing Cell Type: B cell =========================\n",
      "  - Intervention base: B cell_1.0\n",
      "  - Hold-out targets: ['B cell_3.0', 'B cell_10.0']\n",
      "Splitting data with simplified logic...\n",
      "\n",
      "========================= Processing Cell Type: T cell =========================\n",
      "  - Intervention base: T cell_1.0\n",
      "  - Hold-out targets: ['T cell_3.0', 'T cell_10.0']\n",
      "Splitting data with simplified logic...\n",
      "\n",
      "========================= Processing Cell Type: centrilobular region hepatocyte =========================\n",
      "  - Intervention base: centrilobular region hepatocyte_1.0\n",
      "  - Hold-out targets: ['centrilobular region hepatocyte_3.0', 'centrilobular region hepatocyte_10.0']\n",
      "Splitting data with simplified logic...\n",
      "\n",
      "========================= Processing Cell Type: cholangiocyte =========================\n",
      "  - Intervention base: cholangiocyte_1.0\n",
      "  - Hold-out targets: ['cholangiocyte_3.0', 'cholangiocyte_10.0']\n",
      "Splitting data with simplified logic...\n",
      "Skipping 'cholangiocyte': Intervention set (80) or test set (239) is smaller than 1000 cells.\n",
      "\n",
      "========================= Processing Cell Type: endothelial cell of hepatic sinusoid =========================\n",
      "  - Intervention base: endothelial cell of hepatic sinusoid_1.0\n",
      "  - Hold-out targets: ['endothelial cell of hepatic sinusoid_3.0', 'endothelial cell of hepatic sinusoid_10.0']\n",
      "Splitting data with simplified logic...\n",
      "\n",
      "========================= Processing Cell Type: hepatic portal fibroblast =========================\n",
      "  - Intervention base: hepatic portal fibroblast_1.0\n",
      "  - Hold-out targets: ['hepatic portal fibroblast_3.0', 'hepatic portal fibroblast_10.0']\n",
      "Splitting data with simplified logic...\n",
      "Skipping 'hepatic portal fibroblast': Intervention set (37) or test set (180) is smaller than 1000 cells.\n",
      "\n",
      "========================= Processing Cell Type: hepatic stellate cell =========================\n",
      "  - Intervention base: hepatic stellate cell_1.0\n",
      "  - Hold-out targets: ['hepatic stellate cell_3.0', 'hepatic stellate cell_10.0']\n",
      "Splitting data with simplified logic...\n",
      "\n",
      "========================= Processing Cell Type: liver dendritic cell =========================\n",
      "  - Intervention base: liver dendritic cell_1.0\n",
      "  - Hold-out targets: ['liver dendritic cell_3.0', 'liver dendritic cell_10.0']\n",
      "Splitting data with simplified logic...\n",
      "Skipping 'liver dendritic cell': Intervention set (58) or test set (244) is smaller than 1000 cells.\n",
      "\n",
      "========================= Processing Cell Type: macrophage =========================\n",
      "  - Intervention base: macrophage_1.0\n",
      "  - Hold-out targets: ['macrophage_3.0', 'macrophage_10.0']\n",
      "Splitting data with simplified logic...\n",
      "\n",
      "========================= Processing Cell Type: neutrophil =========================\n",
      "  - Intervention base: neutrophil_1.0\n",
      "  - Hold-out targets: ['neutrophil_3.0', 'neutrophil_10.0']\n",
      "Splitting data with simplified logic...\n",
      "Skipping 'neutrophil': Intervention set (46) or test set (154) is smaller than 1000 cells.\n",
      "\n",
      "========================= Processing Cell Type: periportal region hepatocyte =========================\n",
      "  - Intervention base: periportal region hepatocyte_1.0\n",
      "  - Hold-out targets: ['periportal region hepatocyte_3.0', 'periportal region hepatocyte_10.0']\n",
      "Splitting data with simplified logic...\n",
      "\n",
      "\n",
      "============================== FINAL RESULTS SUMMARY ==============================\n",
      "No cell types met the criteria to be processed.\n"
     ]
    }
   ],
   "source": [
    "# Discover all base cell types from the data\n",
    "base_cell_types = sorted(list(set(adata.obs['cell_types_L2'])))\n",
    "all_dose_labels = adata.obs['L2_dose'].unique()\n",
    "\n",
    "all_results = {}\n",
    "all_predictions = {}\n",
    "\n",
    "cell_types = []\n",
    "# Main loop over each discovered cell type\n",
    "for cell_type in base_cell_types:\n",
    "    print(f\"\\n{'='*25} Processing Cell Type: {cell_type} {'='*25}\")\n",
    "\n",
    "    # --- Define hard-coded labels for the experiment ---\n",
    "    mod_label = f\"{cell_type}_1.0\"\n",
    "    hold_out_labels = [f\"{cell_type}_3.0\", f\"{cell_type}_10.0\"]\n",
    "    required_labels = [mod_label] + hold_out_labels\n",
    "\n",
    "    # --- Check if all required dose labels exist for this cell type ---\n",
    "    if not all(label in all_dose_labels for label in required_labels):\n",
    "        print(f\"Skipping '{cell_type}': Does not have all required dose labels (1.0, 3.0, 10.0).\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"  - Intervention base: {mod_label}\")\n",
    "    print(f\"  - Hold-out targets: {hold_out_labels}\")\n",
    "\n",
    "    # Split data and validate set sizes\n",
    "    # In a real scenario, you'd use your actual split_data function\n",
    "    # adata_sub, adata_train, adata_test, adata_inter = split_data(...)\n",
    "    \n",
    "    # Using dummy splits based on the full adata object for this script\n",
    "   # In reality, this would exclude hold_out_labels\n",
    "    adata, adata_train, adata_test, adata_inter = split_data(\n",
    "        adata, hold_out_labels, mod_label, label_key = 'L2_dose'\n",
    "    )\n",
    "    \n",
    "    if len(adata_inter.X) < 300 or len(adata_test.X) < 300:\n",
    "        print(f\"Skipping '{cell_type}': Intervention set ({len(adata_inter.X)}) or test set ({len(adata_test.X)}) is smaller than 1000 cells.\")\n",
    "        continue\n",
    "\n",
    "    cell_types.append(cell_type)\n",
    "\n",
    "    if False:\n",
    "        print(f\"  - Train set: {len(adata_train.X)} cells\")\n",
    "        print(f\"  - Intervention set: {len(adata_inter.X)} cells\")\n",
    "        print(f\"  - Ground Truth set: {len(adata_test.X)} cells\")\n",
    "\n",
    "        # Preprocessing (PCA)\n",
    "        pc_transform = sklearn.decomposition.PCA(n_components=128).fit(adata_train.X)\n",
    "        for x_data in [adata, adata_train, adata_test, adata_inter]:\n",
    "            x_data.obsm[OBSM_KEY] = pc_transform.transform(x_data.X)\n",
    "\n",
    "        # Define Intervention Plan\n",
    "        interventions = []\n",
    "        for label in hold_out_labels:\n",
    "            target_dose_value = adata_test[adata_test.obs['L2_dose'] == label].obsm[SOFT_CONCEPT_KEY]['dose'].astype(float).mean()\n",
    "            interventions.append({'concept': 'dose', 'value': target_dose_value, 'label': label})\n",
    "\n",
    "        # --- Method 1: scCBGM ---\n",
    "        cbgm_model = train_cbgm(adata_train.copy(), hard_concept_key=HARD_CONCEPT_KEY, soft_concept_key=SOFT_CONCEPT_KEY)\n",
    "        \n",
    "        pred_adata_cbgm =[]\n",
    "        for intervention in interventions:\n",
    "            pred_adata_cbgm.append(pred_cbgm(cbgm_model, adata_inter.copy(), hard_concept_key=HARD_CONCEPT_KEY, soft_concept_key=SOFT_CONCEPT_KEY,\n",
    "                                    interventions={intervention['concept']: intervention['value']}))\n",
    "        \n",
    "        # --- Method 2: CB-FM with Learned Concepts ---\n",
    "        adata_with_concepts = get_learned_concepts(cbgm_model, adata.copy(), hard_concept_key=HARD_CONCEPT_KEY, soft_concept_key=SOFT_CONCEPT_KEY)\n",
    "        adata_train.obsm['scCBGM_concepts'] = adata_with_concepts[adata_train.obs.index].obsm['scCBGM_concepts']\n",
    "        adata_inter.obsm['scCBGM_concepts'] = adata_with_concepts[adata_inter.obs.index].obsm['scCBGM_concepts']\n",
    "        \n",
    "        cb_fm_model = train_cb_fm(adata_train.copy(), concept_key='scCBGM_concepts', obsm_key=OBSM_KEY)\n",
    "        \n",
    "        pred_adata_fm_edit = []\n",
    "        pred_adata_fm_guid = []\n",
    "        for intervention in interventions:\n",
    "            pred_adata_fm_edit.append(pred_cb_fm(cb_fm_model, adata_inter.copy(), concept_key='scCBGM_concepts', \n",
    "                                        obsm_key=OBSM_KEY, \n",
    "                                        edit_concept=intervention['concept'],\n",
    "                                        edit_value=intervention['value'], \n",
    "                                        edit=True))\n",
    "            pred_adata_fm_guid.append(pred_cb_fm(cb_fm_model, adata_inter.copy(), \n",
    "                                        concept_key='scCBGM_concepts', \n",
    "                                        obsm_key=OBSM_KEY, \n",
    "                                        edit_concept=intervention['concept'], \n",
    "                                        edit_value=intervention['value'], \n",
    "                                        edit=False))\n",
    "        \n",
    "        # --- Method 3: FM with Raw Concepts ---\n",
    "        fm_raw_model = train_raw_fm(adata_train.copy(), concept_key='concepts', obsm_key=OBSM_KEY)\n",
    "        \n",
    "        pred_adata_raw_fm_edit = []\n",
    "        pred_adata_raw_fm_guid = []\n",
    "        for intervention in interventions:\n",
    "            pred_adata_raw_fm_edit.append(pred_raw_fm(fm_raw_model, adata_inter.copy(), concept_key='concepts', \n",
    "                                        obsm_key=OBSM_KEY, \n",
    "                                        edit_concept=intervention['concept'],\n",
    "                                        edit_value=intervention['value'], \n",
    "                                        edit=True))\n",
    "            pred_adata_raw_fm_guid.append(pred_raw_fm(fm_raw_model, adata_inter.copy(), \n",
    "                                        concept_key='concepts', \n",
    "                                        obsm_key=OBSM_KEY, \n",
    "                                        edit_concept=intervention['concept'], \n",
    "                                        edit_value=intervention['value'], \n",
    "                                        edit=False))\n",
    "\n",
    "        # Evaluate and store results for the current cell type\n",
    "        cell_type_results = {}\n",
    "        cell_type_predictions = {}\n",
    "        \n",
    "        for i, intervention in enumerate(interventions):\n",
    "            intervention_label = intervention['label']\n",
    "            print(f\"  - Evaluating intervention for target: {intervention_label}\")\n",
    "\n",
    "            intervention_adata = adata_test[adata_test.obs['L2_dose'] == intervention_label]\n",
    "\n",
    "            predictions_for_ivn = {\n",
    "                'scCBGM': pred_adata_cbgm[i],\n",
    "                'CB-FM (edit)': pred_adata_fm_edit[i],\n",
    "                'CB-FM (guided)': pred_adata_fm_guid[i],\n",
    "                'Raw-FM (edit)': pred_adata_raw_fm_edit[i],\n",
    "                'Raw-FM (guided)': pred_adata_raw_fm_guid[i]\n",
    "            }\n",
    "            cell_type_predictions[intervention_label] = predictions_for_ivn\n",
    "\n",
    "            mmd_scores = {}\n",
    "            pre_computed_mmd_train = -1\n",
    "            for name, pred_adata in predictions_for_ivn.items():\n",
    "                if pre_computed_mmd_train < 0:\n",
    "                    val = clab.evaluation.interventions.evaluate_intervention_mmd_with_target(\n",
    "                        x_train=adata_train.obsm[OBSM_KEY],\n",
    "                        x_ivn=pred_adata.obsm[OBSM_KEY],\n",
    "                        x_target=intervention_adata.obsm[OBSM_KEY],\n",
    "                        labels_train=adata_train.obs['L2_dose'].values\n",
    "                    )\n",
    "                    pre_computed_mmd_train = val['pre_computed_mmd_train']\n",
    "                else:\n",
    "                    val = clab.evaluation.interventions.evaluate_intervention_mmd_with_target(\n",
    "                        x_train=adata_train.obsm[OBSM_KEY],\n",
    "                        x_ivn=pred_adata.obsm[OBSM_KEY],\n",
    "                        x_target=intervention_adata.obsm[OBSM_KEY],\n",
    "                        labels_train=adata_train.obs['L2_dose'].values,\n",
    "                        pre_computed_mmd_train=pre_computed_mmd_train\n",
    "                    )\n",
    "                \n",
    "                mmd_ratio = val['mmd_ratio']\n",
    "                mmd_scores[name] = mmd_ratio\n",
    "            \n",
    "            cell_type_results[intervention_label] = mmd_scores\n",
    "\n",
    "        print(f\"Results for cell type '{cell_type}':\")\n",
    "        results_df = pd.DataFrame(cell_type_results).T\n",
    "        print(results_df.to_string())\n",
    "\n",
    "        all_results[cell_type] = cell_type_results\n",
    "        all_predictions[cell_type] = cell_type_predictions\n",
    "\n",
    "# Final Summary Report\n",
    "print(\"\\n\\n\" + \"=\"*30 + \" FINAL RESULTS SUMMARY \" + \"=\"*30)\n",
    "\n",
    "summary_data = []\n",
    "for cell_type, interventions_dict in all_results.items():\n",
    "    for intervention_label, models_dict in interventions_dict.items():\n",
    "        row = {'cell_type': cell_type, 'intervention_target': intervention_label}\n",
    "        row.update(models_dict)\n",
    "        summary_data.append(row)\n",
    "\n",
    "if not summary_data:\n",
    "    print(\"No cell types met the criteria to be processed.\")\n",
    "else:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(summary_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884f068",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d0b4533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B cell',\n",
       " 'T cell',\n",
       " 'centrilobular region hepatocyte',\n",
       " 'endothelial cell of hepatic sinusoid',\n",
       " 'hepatic stellate cell',\n",
       " 'macrophage',\n",
       " 'periportal region hepatocyte']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3279107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa92f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16634f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02379fca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beffd1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86833cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6960a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8d7fede",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d5f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83159598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(adata_train, adata_inter, adata_test, pred_adata, obsm_key = 'X_pca', title = \"UMAP Plot\"):\n",
    "\n",
    "    adata_train.obs['split'] = 'train'\n",
    "    adata_train[adata_inter.obs_names].obs['split'] = 'intervention'\n",
    "\n",
    "    adata_test.obs['split'] = 'held out as GT'\n",
    "    pred_adata.obs['split'] = 'intervened on'\n",
    "\n",
    "\n",
    "    plot_adata = ad.concat([adata_train, adata_test, pred_adata])\n",
    "    sc.pp.neighbors(plot_adata, use_rep=obsm_key)\n",
    "    sc.tl.umap(plot_adata)\n",
    "\n",
    "    sc.pl.umap(\n",
    "        plot_adata,\n",
    "        color=['stim', 'split', 'cell_types_L2'],\n",
    "        wspace=0.4,\n",
    "        size=20,\n",
    "        legend_fontsize=12,\n",
    "        title=title,\n",
    "        frameon=False,\n",
    "        ncols=3,\n",
    "        show=False\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(adata_train, adata_inter, adata_test, pred_adata_fm_edit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb9ca61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conceptlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
