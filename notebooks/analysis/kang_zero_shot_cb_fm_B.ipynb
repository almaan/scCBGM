{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ddf8db5",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225a171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbd528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conceptlab as clab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import scipy.spatial\n",
    "import matplotlib.patches as mpatches\n",
    "import string\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17dc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/braid/havivd/scgen/kang.h5ad'\n",
    "MODEL_PATH = '/braid/havivd/scgen/kang_model_params.pth'\n",
    "USE_SAVED_MODEL = False\n",
    "OVERWRITE_SAVED_MODEL = False\n",
    "USE_PC = True\n",
    "Z_SCORE = False\n",
    "CONCEPT_KEY = 'concepts'\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7106c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d498a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plotting Configuration ---\n",
    "CT_CMAP = {\n",
    "    'B cells': \"#e91111\", 'CD4 T cells': '#048757', 'CD8 T cells': '#9cdb97',\n",
    "    'CD14+ Monocytes': '#90e0ef', 'Dendritic cells': '#ffb72a',\n",
    "    'FCGR3A+ Monocytes': '#b18bda', 'Megakaryocytes': '#c5c5b6', 'NK cells': '#51696c'\n",
    "}\n",
    "STIM_CMAP = {'ctrl': '#fcb6b1', 'stim': '#c44536'}\n",
    "# IDENT_CMAP = {\n",
    "#     'train': '#676765', 'held out for intervention': '#c84639',\n",
    "#     'held out as GT': '#048757', 'intervened on': '#06d400'\n",
    "# }\n",
    "\n",
    "IDENT_CMAP = {\n",
    "    'train': '#676765', 'intervention': '#c84639','held out for intervention': '#c84639',\n",
    "    'held out as GT': '#048757', 'intervened on': '#06d400'\n",
    "}\n",
    "\n",
    "TITLE_MAP = {'cell': 'Cell Type', 'stim': 'State', 'ident': 'Split'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1da2c3",
   "metadata": {},
   "source": [
    "# DATA LOADING AND PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f65d663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_data_for_counterfactuals(adata, hold_out_label, mod_label, p_intervention=0.2):\n",
    "#     \"\"\"Splits data into train, intervention, and ground truth sets.\"\"\"\n",
    "#     print(\"Splitting data for counterfactual experiment...\")\n",
    "#     labels = adata.obs['cell_stim']\n",
    "#     is_test = (labels == hold_out_label)\n",
    "#     is_inter_pool = (labels == mod_label)\n",
    "\n",
    "#     # Create a random mask to select a subset for intervention\n",
    "#     inter_mask = np.random.binomial(1, p=p_intervention, size=is_inter_pool.sum()).astype(bool)\n",
    "#     is_inter = np.zeros_like(labels, dtype=bool)\n",
    "#     is_inter[is_inter_pool] = inter_mask\n",
    "    \n",
    "#     is_train = ~is_test & ~is_inter\n",
    "\n",
    "#     # Create AnnData objects for each split\n",
    "#     adata_train = adata[is_train].copy()\n",
    "#     adata_test = adata[is_test].copy()\n",
    "#     adata_inter = adata[is_inter].copy()\n",
    "\n",
    "#     # Store split identifiers in the original object for later merging\n",
    "#     ident_vec = np.array(['train'] * len(adata)).astype('<U32')\n",
    "#     ident_vec[is_test] = 'held out as GT'\n",
    "#     ident_vec[is_inter] = 'held out for intervention'\n",
    "#     adata.obs['ident'] = ident_vec\n",
    "    \n",
    "#     print(f\"Train set: {len(adata_train)} cells\")\n",
    "#     print(f\"Intervention set: {len(adata_inter)} cells\")\n",
    "#     print(f\"Ground Truth set: {len(adata_test)} cells\")\n",
    "\n",
    "#     return adata, adata_train, adata_test, adata_inter\n",
    "\n",
    "\n",
    "def split_data(adata, hold_out_label, mod_label):\n",
    "    \"\"\"\n",
    "    Splits data into train, intervention, and ground truth sets.\n",
    "\n",
    "    - Ground Truth: All cells with the `hold_out_label`.\n",
    "    - Intervention: All cells with the `mod_label`.\n",
    "    - Train: All remaining cells.\n",
    "    \"\"\"\n",
    "    print(\"Splitting data with simplified logic...\")\n",
    "    labels = adata.obs['cell_stim']\n",
    "\n",
    "    # Define the three disjoint sets based on their labels\n",
    "    is_test = (labels == hold_out_label)\n",
    "    is_inter = (labels == mod_label)\n",
    "    is_train = ~is_test\n",
    "\n",
    "    # Create AnnData objects for each split\n",
    "    adata_train = adata[is_train].copy()\n",
    "    adata_test = adata[is_test].copy()\n",
    "    adata_inter = adata[is_inter].copy()\n",
    "\n",
    "    # Store split identifiers in the original object\n",
    "    ident_vec = np.array(['train'] * len(adata)).astype('<U32')\n",
    "    ident_vec[is_test] = 'held out as GT'\n",
    "    ident_vec[is_inter] = 'intervention'\n",
    "    adata.obs['ident'] = ident_vec\n",
    "    \n",
    "    print(f\"Train set: {len(adata_train)} cells\")\n",
    "    print(f\"Intervention set: {len(adata_inter)} cells\")\n",
    "    print(f\"Ground Truth set: {len(adata_test)} cells\")\n",
    "\n",
    "    return adata, adata_train, adata_test, adata_inter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4afc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce377a4a",
   "metadata": {},
   "source": [
    "# MODELING & PREDICTION METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8637333d",
   "metadata": {},
   "source": [
    "## Method 1: scCBGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117fa200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_method_1_cbgm(adata_train, pc = USE_PC, z_score = Z_SCORE):\n",
    "    \"\"\"Trains and returns the scCBGM model.\"\"\"\n",
    "    print(\"Training scCBGM model...\")\n",
    "\n",
    "    # --- MODIFICATION START ---\n",
    "    # Conditionally set the data source and input dimension based on the 'pca' flag\n",
    "    if(pc):\n",
    "        data_matrix = adata_train.obsm['X_pca']\n",
    "    else:\n",
    "        data_matrix = adata_train.X\n",
    "        if(z_score):\n",
    "            data_matrix = (data_matrix - adata_train.var['mean'].to_numpy()[None, :]) / adata_train.var['std'].to_numpy()[None, :]  # Z-score normalization\n",
    "\n",
    "    # --- MODIFICATION END ---\n",
    "\n",
    "    torch.set_flush_denormal(True)\n",
    "\n",
    "    config = OmegaConf.create(dict(\n",
    "        has_cbm=True, \n",
    "        lr=5e-4, \n",
    "        hidden_dim=1024, \n",
    "        n_layers = 4,\n",
    "        beta=1e-5,\n",
    "        input_dim=data_matrix.shape[-1],  # <-- Use the dynamically set input dimension\n",
    "        latent_dim=128,\n",
    "        n_concepts=adata_train.obsm[CONCEPT_KEY].shape[1],\n",
    "        min_bottleneck_size=128, independent_training=True,\n",
    "        concepts_hp=0.005, orthogonality_hp=0.2, use_soft_concepts=False\n",
    "    ))\n",
    "    model = clab.models.scCBGM(config)\n",
    "\n",
    "    model.train_loop(\n",
    "        data=torch.from_numpy(data_matrix.astype(np.float32)),\n",
    "        concepts=torch.from_numpy(adata_train.obsm[CONCEPT_KEY].to_numpy().astype(np.float32)),\n",
    "        num_epochs=1000, batch_size=128, lr=3e-4,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def predict_with_method_1_cbgm(model, adata_inter, hold_out_label, pc = USE_PC):\n",
    "    \"\"\"Performs intervention using a trained scCBGM model.\"\"\"\n",
    "    print(\"Performing intervention with scCBGM...\")\n",
    "    if(pc):\n",
    "        x_intervene_on =  torch.tensor(adata_inter.obsm['X_pca'], dtype=torch.float32)\n",
    "    else:\n",
    "        x_intervene_on = torch.tensor(adata_inter.X, dtype=torch.float32)\n",
    "    c_intervene_on = adata_inter.obsm[CONCEPT_KEY].to_numpy().astype(np.float32)\n",
    "\n",
    "    # Define the intervention by creating a mask and new concept values\n",
    "    mask = torch.zeros(c_intervene_on.shape, dtype=torch.float32)\n",
    "    mask[:, -1] = 1  # Intervene on the last concept (stim)\n",
    "    \n",
    "    inter_concepts = torch.tensor(c_intervene_on, dtype=torch.float32)\n",
    "    inter_concepts[:, -1] = 1 # Set stim concept to 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inter_preds = model.intervene(x_intervene_on.to('cuda'), mask=mask.to('cuda'), concepts=inter_concepts.to('cuda'))\n",
    "    \n",
    "    inter_preds = inter_preds['x_pred'].cpu().numpy()\n",
    "    \n",
    "    if(pc):\n",
    "        x_inter_preds = adata_inter.uns['pc_transform'].inverse_transform(inter_preds)\n",
    "    else:\n",
    "        x_inter_preds = inter_preds\n",
    "\n",
    "    pred_adata = ad.AnnData(x_inter_preds, var=adata_inter.var)\n",
    "    pred_adata.obs['ident'] = 'intervened on'\n",
    "    pred_adata.obs['cell_stim'] = hold_out_label + '*'\n",
    "\n",
    "    if(pc):\n",
    "        pred_adata.obsm['X_pca'] = inter_preds\n",
    "    return pred_adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec223ed8",
   "metadata": {},
   "source": [
    "##  Method 2: Flow Matching with Learned Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c4957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learned_concepts(scCBGM_model, adata_full, pc = USE_PC):\n",
    "    \"\"\"Uses a trained scCBGM to generate learned concepts for all data.\"\"\"\n",
    "    print(\"Generating learned concepts from scCBGM...\")\n",
    "\n",
    "    if(pc):\n",
    "        all_x = torch.tensor(adata_full.obsm['X_pca'], dtype=torch.float32).to('cuda')\n",
    "    else:\n",
    "        all_x = torch.tensor(adata_full.X, dtype=torch.float32).to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        enc = scCBGM_model.encode(all_x)\n",
    "        adata_full.obsm['scCBGM_concepts_known'] = scCBGM_model.cb_concepts_layers(enc['mu']).cpu().numpy()\n",
    "        adata_full.obsm['scCBGM_concepts_unknown'] = scCBGM_model.cb_unk_layers(enc['mu']).cpu().numpy()\n",
    "\n",
    "    adata_full.obsm['scCBGM_concepts'] = np.concatenate([adata_full.obsm['scCBGM_concepts_known'], adata_full.obsm['scCBGM_concepts_unknown']], axis=1)\n",
    "    return adata_full\n",
    "\n",
    "def train_method_2_fm_learned(adata_train, pc = USE_PC, z_score = Z_SCORE):\n",
    "    \"\"\"Trains and returns the CB-FM model using learned concepts.\"\"\"\n",
    "    print(\"Training Conditonal Flow Model\")\n",
    "\n",
    "    if(pc):\n",
    "        data_matrix = adata_train.obsm['X_pca']\n",
    "    else:\n",
    "        data_matrix = adata_train.X\n",
    "        if(z_score):\n",
    "            data_matrix = (data_matrix - adata_train.var['mean'].to_numpy()[None, :]) / adata_train.var['std'].to_numpy()[None, :]  # Z-score normalization\n",
    "\n",
    "    config = dict(\n",
    "        input_dim=data_matrix.shape[1],\n",
    "        hidden_dim=1024,\n",
    "        latent_dim=128,\n",
    "        n_concepts=adata_train.obsm['scCBGM_concepts'].shape[1],\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "        p_uncond = 0.1)\n",
    "\n",
    "    fm_model = clab.models.cond_fm.Cond_FM(config=config)\n",
    "\n",
    "    fm_model.train_loop(\n",
    "        data=torch.from_numpy(data_matrix.astype(np.float32)),\n",
    "        concepts=torch.from_numpy(adata_train.obsm['scCBGM_concepts'].astype(np.float32)),\n",
    "        num_epochs=1000, batch_size=128, lr=3e-4,\n",
    "    )\n",
    "    return fm_model\n",
    "\n",
    "\n",
    "\n",
    "def predict_with_method_2_fm_learned(model, adata_inter, hold_out_label, pc = USE_PC, z_score = Z_SCORE, ):\n",
    "    \"\"\"Performs intervention using a trained learned-concept CB-FM model.\"\"\"\n",
    "    print(\"Performing intervention with CB-FM (learned)...\")\n",
    "    c_known_inter = torch.from_numpy(adata_inter.obsm['scCBGM_concepts_known'].astype(np.float32))\n",
    "    c_unknown_inter = torch.from_numpy(adata_inter.obsm['scCBGM_concepts_unknown'].astype(np.float32))\n",
    "    \n",
    "    inter_concepts_known = c_known_inter.clone()\n",
    "    inter_concepts_known[:, -1] = 1 # Set stim concept to 1\n",
    "    \n",
    "    if(pc):\n",
    "        x_inter = adata_inter.obsm['X_pca']\n",
    "    else:\n",
    "        x_inter = adata_inter.X\n",
    "        if(z_score):\n",
    "            x_inter = (x_inter - adata_inter.var['mean'].to_numpy()[None, :]) / adata_inter.var['std'].to_numpy()[None, :]\n",
    "\n",
    "    init_concepts = np.concatenate([c_known_inter, c_unknown_inter], axis=1)\n",
    "    edit_concepts = np.concatenate([inter_concepts_known, c_unknown_inter], axis=1)\n",
    "\n",
    "    inter_preds = model.edit(\n",
    "             x = torch.from_numpy(x_inter.astype(np.float32)).to('cuda'),\n",
    "             c = torch.from_numpy(init_concepts.astype(np.float32)).to('cuda'),\n",
    "             c_prime = torch.from_numpy(edit_concepts.astype(np.float32)).to('cuda'),\n",
    "             t_edit = 0.01,\n",
    "             n_steps = 1000,\n",
    "             w_cfg_forward = 1.5,\n",
    "             w_cfg_backward = 1.0,\n",
    "             noise_add = 0.0)\n",
    "    \n",
    "    inter_preds = inter_preds.detach().cpu().numpy()\n",
    "\n",
    "    if(pc):\n",
    "        x_inter_preds = adata_inter.uns['pc_transform'].inverse_transform(inter_preds)\n",
    "    else:\n",
    "        x_inter_preds = inter_preds\n",
    "\n",
    "    if(z_score):\n",
    "        x_inter_preds = (x_inter_preds * adata_inter.var['std'].to_numpy()[None, :]) + adata_inter.var['mean'].to_numpy()[None, :]\n",
    "\n",
    "    pred_adata = ad.AnnData(x_inter_preds, var=adata_inter.var)\n",
    "    pred_adata.obs['ident'] = 'intervened on'\n",
    "    pred_adata.obs['cell_stim'] = hold_out_label + '*'\n",
    "\n",
    "    if(pc):\n",
    "        pred_adata.obsm['X_pca'] = inter_preds\n",
    "\n",
    "    return pred_adata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6bf927",
   "metadata": {},
   "source": [
    "## Method 3: Concept Flows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b8e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_method_3_concept_flows(adata_train, pc = USE_PC, z_score = Z_SCORE):\n",
    "    \"\"\"Trains and returns the CB-FM model using learned concepts.\"\"\"\n",
    "    print(\"Training Concept Flow Model\")\n",
    "\n",
    "    if(pc):\n",
    "        data_matrix = adata_train.obsm['X_pca']\n",
    "    else:\n",
    "        data_matrix = adata_train.X\n",
    "        if(z_score):\n",
    "            data_matrix = (data_matrix - adata_train.var['mean'].to_numpy()[None, :]) / adata_train.var['std'].to_numpy()[None, :]  # Z-score normalization\n",
    "            \n",
    "    config = dict(\n",
    "        input_dim=data_matrix.shape[1],\n",
    "        hidden_dim=1024,\n",
    "        latent_dim=128,\n",
    "        n_concepts=adata_train.obsm[CONCEPT_KEY].to_numpy().shape[1],\n",
    "        n_unkown = 128,\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "        p_uncond=0.1)\n",
    "\n",
    "    fm_model = clab.models.concept_fm.Concept_FM(config=config)\n",
    "\n",
    "    fm_model.train_loop(\n",
    "        data=torch.from_numpy(data_matrix.astype(np.float32)),\n",
    "        concepts=torch.from_numpy(adata_train.obsm[CONCEPT_KEY].to_numpy().astype(np.float32)),\n",
    "        num_epochs=1000, batch_size=128, lr=3e-4,\n",
    "    )\n",
    "    return fm_model\n",
    "\n",
    "def predict_with_method_3_concept_flows(model, adata_inter, hold_out_label, pc = USE_PC, z_score = Z_SCORE):\n",
    "    \"\"\"Performs intervention using a trained scCBGM model.\"\"\"\n",
    "    print(\"Performing intervention with concept flow...\")\n",
    "\n",
    "\n",
    "    if(pc):\n",
    "        data_matrix = adata_inter.obsm['X_pca']\n",
    "    else:\n",
    "        data_matrix = adata_inter.X\n",
    "        if(z_score):\n",
    "            data_matrix = (data_matrix - adata_inter.var['mean'].to_numpy()[None, :]) / adata_inter.var['std'].to_numpy()[None, :]  # Z-score normalization\n",
    "\n",
    "    x_intervene_on = torch.from_numpy(data_matrix)\n",
    "    c_intervene_on = torch.from_numpy(adata_inter.obsm[CONCEPT_KEY].to_numpy().astype(np.float32))\n",
    "\n",
    "    \n",
    "    inter_concepts_known = c_intervene_on.clone()\n",
    "    inter_concepts_known[:, -1] = 1 # Set stim concept to 1\n",
    "    \n",
    "    # Define the intervention by creating a mask and new concept values\n",
    "    mask = torch.zeros(c_intervene_on.shape, dtype=torch.float32)\n",
    "    mask[:, -1] = 1  # Intervene on the last concept (stim)\n",
    "    \n",
    "    inter_concepts = torch.tensor(c_intervene_on, dtype=torch.float32)\n",
    "    inter_concepts[:, -1] = 1 # Set stim concept to 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inter_preds = model.intervene(x_intervene_on.to('cuda'), mask=mask.to('cuda'), concepts=inter_concepts.to('cuda'))\n",
    "\n",
    "    inter_preds = inter_preds.detach().cpu().numpy()\n",
    "\n",
    "    if(pc):\n",
    "        x_inter_preds = adata_inter.uns['pc_transform'].inverse_transform(inter_preds)\n",
    "    else:\n",
    "        x_inter_preds = inter_preds\n",
    "\n",
    "    if(z_score):\n",
    "        x_inter_preds = (x_inter_preds * adata_inter.var['std'].to_numpy()[None, :]) + adata_inter.var['mean'].to_numpy()[None, :]\n",
    "\n",
    "    pred_adata = ad.AnnData(x_inter_preds, var=adata_inter.var)\n",
    "    pred_adata.obs['ident'] = 'intervened on'\n",
    "    pred_adata.obs['cell_stim'] = hold_out_label + '*'\n",
    "\n",
    "    if(pc):\n",
    "        pred_adata.obsm['X_pca'] = inter_preds\n",
    "    return pred_adata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db46e42",
   "metadata": {},
   "source": [
    "## Method 4: Flow Matching with Raw Concepts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_method_4_fm_raw(adata_train, pc = USE_PC, z_score = Z_SCORE):\n",
    "    \"\"\"Trains and returns the CB-FM model using learned concepts.\"\"\"\n",
    "\n",
    "    print(\"Training Conditonal Flow Model\")\n",
    "\n",
    "    if(pc):\n",
    "        data_matrix = adata_train.obsm['X_pca']\n",
    "    else:\n",
    "        data_matrix = adata_train.X\n",
    "        if(z_score):\n",
    "            data_matrix = (data_matrix - adata_train.var['mean'].to_numpy()[None, :]) / adata_train.var['std'].to_numpy()[None, :]  # Z-score normalization\n",
    "\n",
    "    config = dict(\n",
    "        input_dim=data_matrix.shape[1],\n",
    "        hidden_dim=1024,\n",
    "        latent_dim=128,\n",
    "        n_concepts=adata_train.obsm[CONCEPT_KEY].to_numpy().shape[1],\n",
    "        n_layers=4,\n",
    "        p_uncond = 0.0,\n",
    "        dropout=0.1)\n",
    "\n",
    "    fm_model = clab.models.cond_fm.Cond_FM(config=config)\n",
    "\n",
    "    fm_model.train_loop(\n",
    "        data=torch.from_numpy(data_matrix.astype(np.float32)),\n",
    "        concepts=torch.from_numpy(adata_train.obsm[CONCEPT_KEY].to_numpy().astype(np.float32)),\n",
    "        num_epochs=1000, batch_size=128, lr=3e-4,\n",
    "    )\n",
    "    return fm_model\n",
    "\n",
    "def predict_with_method_4_fm_raw(model, adata_inter, hold_out_label, pc = USE_PC, z_score = Z_SCORE):\n",
    "    \"\"\"Performs intervention using a trained raw-concept CB-FM model.\"\"\"\n",
    "    print(\"Performing intervention with CB-FM (raw)...\")\n",
    "    c_intervene_on = torch.from_numpy(adata_inter.obsm[CONCEPT_KEY].to_numpy().astype(np.float32))\n",
    "    inter_concepts = c_intervene_on.clone()\n",
    "    inter_concepts[:, -1] = 1 # Set stim concept to 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inter_preds = model.decode(\n",
    "            h=inter_concepts.to('cuda'),\n",
    "            n_steps=1000,\n",
    "            w_cfg = 1.0\n",
    "        )\n",
    "    inter_preds = inter_preds.detach().cpu().numpy()\n",
    "\n",
    "    if(pc):\n",
    "        x_inter_preds = adata_inter.uns['pc_transform'].inverse_transform(inter_preds)\n",
    "    else:\n",
    "        x_inter_preds = inter_preds\n",
    "\n",
    "    if(z_score):\n",
    "        x_inter_preds = (x_inter_preds * adata_inter.var['std'].to_numpy()[None, :]) + adata_inter.var['mean'].to_numpy()[None, :]\n",
    "\n",
    "    pred_adata = ad.AnnData(x_inter_preds, var=adata_inter.var)\n",
    "    pred_adata.obs['ident'] = 'intervened on'\n",
    "    pred_adata.obs['cell_stim'] = hold_out_label + '*'\n",
    "\n",
    "    if(pc):\n",
    "        pred_adata.obsm['X_pca'] = inter_preds\n",
    "    return pred_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862856c0",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_plot_results(adata_original, pred_adata, method_name, score):\n",
    "    \"\"\"Merges data, runs UMAP, calculates error, and plots the results.\"\"\"\n",
    "    print(f\"Analyzing and plotting results for {method_name}...\")\n",
    "    \n",
    "    # Keep only the original data splits, not the predicted one\n",
    "    adata_to_merge = adata_original[adata_original.obs['ident'] != 'intervened on'].copy()\n",
    "\n",
    "    # Merge original data with the new prediction\n",
    "    adata_merged = ad.concat([adata_to_merge, pred_adata], join='inner', merge='unique')\n",
    "    \n",
    "    # Add other metadata for coloring\n",
    "    adata_merged.obs['cell'] = [label.split('_')[0] for label in adata_merged.obs['cell_stim']]\n",
    "    adata_merged.obs['stim'] = ['stim' if 'stim' in label else 'ctrl' for label in adata_merged.obs['cell_stim']]\n",
    "\n",
    "    # Dimensionality Reduction for visualization\n",
    "    #sc.pp.pca(adata_merged)\n",
    "    \n",
    "    #adata_merged.obsm['X_pca'] = adata_merged.X\n",
    "    # check if obsm has X_pca:\n",
    "\n",
    "    if 'X_pca' in adata_merged.obsm:\n",
    "        print(\"using pca already computed\")\n",
    "    else:\n",
    "        print(\"computing pca\")\n",
    "        sc.pp.pca(adata_merged)\n",
    "    \n",
    "\n",
    "    sc.pp.neighbors(adata_merged)\n",
    "    sc.tl.umap(adata_merged, random_state=RANDOM_SEED)\n",
    "\n",
    "    # # Set plotting order\n",
    "    # adata_merged.obs['ident'] = pd.Categorical(adata_merged.obs['ident'],\n",
    "    #     categories=['train', 'intervention', 'held out as GT', 'intervened on'])\n",
    "\n",
    "    adata_merged.obs['ident'] = pd.Categorical(adata_merged.obs['ident'],\n",
    "    categories=['train', 'intervention', 'held out for intervention', 'held out as GT', 'intervened on'])\n",
    "    \n",
    "    # --- Plotting ---\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(21, 5), constrained_layout=True)\n",
    "    fig.suptitle(f\"Counterfactual Prediction Results: {method_name}\", fontsize=20)\n",
    "    \n",
    "    cmaps = [CT_CMAP, STIM_CMAP, IDENT_CMAP]\n",
    "    color_keys = ['cell', 'stim', 'ident']\n",
    "\n",
    "    for i, (ax, cmap, key) in enumerate(zip(axes, cmaps, color_keys)):\n",
    "        sc.pl.umap(adata_merged, color=key, ax=ax, show=False, palette=cmap, s=10,\n",
    "                   title=f\"{string.ascii_uppercase[i]}) {TITLE_MAP[key]}\")\n",
    "        \n",
    "        # Add error to the title of the last plot\n",
    "        if key == 'ident':\n",
    "            ax.set_title(f\"{ax.get_title()}, rMMD score {score:.2f}\")\n",
    "\n",
    "            # Add intervention arrow\n",
    "            source_coords = adata_merged[adata_merged.obs['ident'] == 'intervention'].obsm['X_umap'].mean(0)\n",
    "            #source_coords = adata_merged[adata_merged.obs['ident'] == 'held out for intervention'].obsm['X_umap'].mean(0)\n",
    "            target_coords = adata_merged[adata_merged.obs['ident'] == 'intervened on'].obsm['X_umap'].mean(0)\n",
    "            arrow = mpatches.FancyArrowPatch(\n",
    "                source_coords, target_coords,\n",
    "                connectionstyle=\"arc3,rad=0.3\", arrowstyle=\"-|>\",\n",
    "                linewidth=2, linestyle='dashed', color=\"black\", mutation_scale=20\n",
    "            )\n",
    "            ax.add_patch(arrow)\n",
    "            \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8c3a1",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b5188",
   "metadata": {},
   "source": [
    "## Proccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc78e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85ddf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading and preprocessing data...\")\n",
    "adata = ad.read_h5ad(DATA_PATH)\n",
    "sc.pp.normalize_total(adata, target_sum=np.median(adata.X.toarray().sum(axis=1)))\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes = 2048, subset=True)\n",
    "\n",
    "adata.X = adata.X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12f121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_out_label = 'B cells_stim'\n",
    "mod_label = 'B cells_ctrl'\n",
    "\n",
    "\n",
    "adata, adata_train, adata_test, adata_inter = split_data(\n",
    "    adata, hold_out_label, mod_label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e564de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.uns['pc_transform'] = sklearn.decomposition.PCA(n_components=80).fit(adata_train.X)\n",
    "\n",
    "for x_data in [adata, adata_train, adata_test, adata_inter]:\n",
    "    x_data.uns['pc_transform'] = adata.uns['pc_transform']\n",
    "    x_data.obsm['X_pca'] = x_data.uns['pc_transform'].transform(x_data.X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c42939",
   "metadata": {},
   "source": [
    "## --- Method 1: scCBGM ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f28af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbgm_model = train_method_1_cbgm(adata_train.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fd5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_adata_cbgm = predict_with_method_1_cbgm(cbgm_model, adata_inter.copy(), hold_out_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cbfm_learned_mmd = clab.evaluation.interventions.evaluate_intervention_mmd_with_target(\n",
    "    x_train=adata_train.obsm['X_pca'] if USE_PC else adata_train.X,\n",
    "    x_ivn=pred_adata_cbgm.obsm['X_pca'] if USE_PC else pred_adata_cbgm.X,\n",
    "    x_target=adata_test.obsm['X_pca'] if USE_PC else adata_test.X,\n",
    "    labels_train=adata_train.obs['cell_stim'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dfb4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_and_plot_results(adata, pred_adata_cbgm, \"Method 1: scCBGM\", score_cbfm_learned_mmd['mmd_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9884f068",
   "metadata": {},
   "source": [
    "## --- Method 2: CB-FM with Learned Concepts ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3279107",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_with_concepts = get_learned_concepts(cbgm_model, adata.copy())\n",
    "# Distribute the newly generated concepts to the training set\n",
    "adata_train.obsm['scCBGM_concepts'] = adata_with_concepts[adata_train.obs.index].obsm['scCBGM_concepts']\n",
    "adata_inter.obsm['scCBGM_concepts'] = adata_with_concepts[adata_inter.obs.index].obsm['scCBGM_concepts']\n",
    "\n",
    "adata_train.obsm['scCBGM_concepts_known'] = adata_with_concepts[adata_train.obs.index].obsm['scCBGM_concepts_known']\n",
    "adata_train.obsm['scCBGM_concepts_unknown'] = adata_with_concepts[adata_train.obs.index].obsm['scCBGM_concepts_unknown']\n",
    "\n",
    "adata_inter.obsm['scCBGM_concepts_known'] = adata_with_concepts[adata_inter.obs.index].obsm['scCBGM_concepts_known']\n",
    "adata_inter.obsm['scCBGM_concepts_unknown'] = adata_with_concepts[adata_inter.obs.index].obsm['scCBGM_concepts_unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa92f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_learned_model = train_method_2_fm_learned(adata_train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16634f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_adata_fm_learned = predict_with_method_2_fm_learned(fm_learned_model, adata_inter.copy(), hold_out_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be13767",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "score_fm_learned_mmd = clab.evaluation.interventions.evaluate_intervention_mmd_with_target(\n",
    "    x_train=adata_train.obsm['X_pca'] if USE_PC else adata_train.X,\n",
    "    x_ivn=pred_adata_fm_learned.obsm['X_pca'] if USE_PC else pred_adata_fm_learned.X,\n",
    "    x_target=adata_test.obsm['X_pca'] if USE_PC else adata_test.X,\n",
    "    labels_train=adata_train.obs['cell_stim'].values,\n",
    "    pre_computed_mmd_train=score_cbfm_learned_mmd['pre_computed_mmd_train']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_fm_learned_mmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ac3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_and_plot_results(adata, pred_adata_fm_learned, \"Method 2: CB-FM (Learned Concepts)\", score_fm_learned_mmd['mmd_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c84f37e",
   "metadata": {},
   "source": [
    "## --- Method 3: Concept Flows ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_flow_model = train_method_3_concept_flows(adata_train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b48c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_adata_concept_flow = predict_with_method_3_concept_flows(concept_flow_model, adata_inter.copy(), hold_out_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ddd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "score_fm_cf_mmd = clab.evaluation.interventions.evaluate_intervention_mmd_with_target(\n",
    "    x_train=adata_train.obsm['X_pca'] if USE_PC else adata_train.X,\n",
    "    x_ivn=pred_adata_concept_flow.obsm['X_pca'] if USE_PC else pred_adata_concept_flow.X,\n",
    "    x_target=adata_test.obsm['X_pca'] if USE_PC else adata_test.X,\n",
    "    labels_train=adata_train.obs['cell_stim'].values,\n",
    "    pre_computed_mmd_train=score_cbfm_learned_mmd['pre_computed_mmd_train']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d88bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_and_plot_results(adata, pred_adata_concept_flow, \"Method 3: Concept Flow\", score_fm_cf_mmd['mmd_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02379fca",
   "metadata": {},
   "source": [
    "## --- Method 4: CB-FM with Raw Concepts ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86833cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_raw_model = train_method_4_fm_raw(adata_train.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_adata_fm_raw = predict_with_method_4_fm_raw(fm_raw_model, adata_inter.copy(), hold_out_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91d5f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_fm_raw_mmd = clab.evaluation.interventions.evaluate_intervention_mmd_with_target(\n",
    "    x_train=adata_train.obsm['X_pca'] if USE_PC else adata_train.X,\n",
    "    x_ivn=pred_adata_fm_raw.obsm['X_pca'] if USE_PC else pred_adata_fm_raw.X,\n",
    "    x_target=adata_test.obsm['X_pca'] if USE_PC else adata_test.X,\n",
    "    labels_train=adata_train.obs['cell_stim'].values,\n",
    "    pre_computed_mmd_train=score_cbfm_learned_mmd['pre_computed_mmd_train']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f730b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_and_plot_results(adata, pred_adata_fm_raw, \"Method 3: CB-FM (Raw Concepts)\",  score_fm_raw_mmd['mmd_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe82d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53668c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2551cfb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4701773c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d91140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d223e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conceptlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
